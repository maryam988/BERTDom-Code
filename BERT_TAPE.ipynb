{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT_TAPE.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"14e0bc9ca8224f9b89114a49f36f9c0c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d24b2787c84942f5afd180ae44105151","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5ddbf6453431410991bd6787576e0be5","IPY_MODEL_01d8ce4a34ab48ed9f483d400dedb386"]}},"d24b2787c84942f5afd180ae44105151":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"600px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"5ddbf6453431410991bd6787576e0be5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_385a3ba9fdc34eda8fd7114a9108e2ee","_dom_classes":[],"description":" 58%","_model_name":"FloatProgressModel","bar_style":"","max":31400,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":18106,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_645ee73dd87f4539a8d7afa819c50718"}},"01d8ce4a34ab48ed9f483d400dedb386":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_80c8e0a303094066a6911c7e42aa1f8c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 18106/31400 [3:18:31&lt;13:46:04,  3.73s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d533b75a00dc4629a3d46d8d57163b0d"}},"385a3ba9fdc34eda8fd7114a9108e2ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"645ee73dd87f4539a8d7afa819c50718":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"80c8e0a303094066a6911c7e42aa1f8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d533b75a00dc4629a3d46d8d57163b0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DMH3zOGmBqXo","executionInfo":{"status":"ok","timestamp":1610182541563,"user_tz":-300,"elapsed":1006,"user":{"displayName":"Akira Blac","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjahauVm3Xisytr3Mhx327sUBpZk09bRao0fxbHnw=s64","userId":"15395188499654194491"}},"outputId":"ff68623e-4553-4fbb-f651-e2fe0667f004"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sat Jan  9 08:55:40 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   28C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZkfKnoHAwyZH"},"source":["pip install tape_proteins >> /dev/null"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"idJCI7egjucD"},"source":["!pip install bert-for-tf2 >> /dev/null"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PbegZ28Hxec_"},"source":["import os\r\n","import math\r\n","import datetime\r\n","import random\r\n","import importlib\r\n","\r\n","# from tqdm import tqdm\r\n","from tqdm.notebook import tqdm as tqdm\r\n","\r\n","import pandas as pd\r\n","import numpy as np\r\n","\r\n","import re\r\n","\r\n","import tensorflow as tf\r\n","from tensorflow import keras\r\n","from  tensorflow.keras.callbacks import EarlyStopping\r\n","\r\n","import bert\r\n","from bert import BertModelLayer\r\n","from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\r\n","from bert.tokenization.bert_tokenization import FullTokenizer\r\n","\r\n","import torch\r\n","from tape import ProteinBertModel, TAPETokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HzQsZ0HCddbs","executionInfo":{"status":"ok","timestamp":1610182562228,"user_tz":-300,"elapsed":1220,"user":{"displayName":"Akira Blac","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjahauVm3Xisytr3Mhx327sUBpZk09bRao0fxbHnw=s64","userId":"15395188499654194491"}},"outputId":"381e73fd-37e9-4916-caed-0c028ba64493"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dbjTjLoxEK4l","executionInfo":{"status":"ok","timestamp":1610182562230,"user_tz":-300,"elapsed":1210,"user":{"displayName":"Akira Blac","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjahauVm3Xisytr3Mhx327sUBpZk09bRao0fxbHnw=s64","userId":"15395188499654194491"}},"outputId":"3058ea9b-fd07-4f16-9fb5-864bba25f366"},"source":["cd \"/content/drive/My Drive/Colab Notebooks NU\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1FqifPUlm6cgaaWF0H2AQqipYJL1XcCct/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8YG1Aal8hmTt"},"source":["import bert_thesis_experiments.utils as utils\r\n","import bert_thesis_experiments.my_models as my_models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z0mgfjMPhqgx"},"source":["seqfile = 'DeepDom_Code/DeepDom-master/processed_seq.txt'; #file name of the processed sequence data (output from dataprocess.pl)\r\n","labelfile= 'DeepDom_Code/DeepDom-master/processed_label.txt'; #file name of the processed label data (output from dataprocess.pl)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xIMBduIQff1Y"},"source":["(ids,seqs) = utils.process_inputseqs(seqfile)\r\n","(ids,labels) = utils.process_inputlabels(labelfile)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FwAJCxcxhy39"},"source":["rawdata = list(zip(seqs,labels))\r\n","random.shuffle(rawdata)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rhonQInGBT2f"},"source":["model = ProteinBertModel.from_pretrained('bert-base')\r\n","tokenizer = TAPETokenizer(vocab='iupac')  # iupac is the vocab for TAPE models, use unirep for the UniRep model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CU6cP-6NyjGa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610182587008,"user_tz":-300,"elapsed":11095,"user":{"displayName":"Akira Blac","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjahauVm3Xisytr3Mhx327sUBpZk09bRao0fxbHnw=s64","userId":"15395188499654194491"}},"outputId":"1387e3eb-43a5-4364-cba0-3f545cfaeaad"},"source":["sequence = rawdata[50][0]\r\n","seq_length = len(sequence)\r\n","print(sequence)\r\n","# token_ids = torch.tensor([np.append(tokenizer.encode(sequence), [0]*3)]) # [0] is pad symbol id\r\n","seq_wo_dash = sequence[:len(sequence) if sequence.find(\"-\") == -1 else sequence.find(\"-\")]\r\n","if seq_length == len(seq_wo_dash):\r\n","  token_ids = torch.tensor([tokenizer.encode(seq_wo_dash[1:-1])])\r\n","else:\r\n","  token_ids = torch.tensor([np.append(tokenizer.encode(seq_wo_dash), [0]*(seq_length-len(seq_wo_dash)-2))], dtype=int)\r\n","print(token_ids)\r\n","output = model(token_ids)\r\n","sequence_output = output[0]\r\n","pooled_output = output[1]\r\n","\r\n","# NOTE: pooled_output is *not* trained for the transformer, do not use\r\n","# w/o fine-tuning. A better option for now is to simply take a mean of\r\n","# the sequence output"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TFLTIPIRLHEPNEFKLRLQEFTFQAFEFNERVEYQFKKSKTNELESPVLSKDFNTTDSNALVDNGIIPSEFLLYLVSMKHKLATNCAIYEVSMKAAIAFHDYELAMTTWKNRGKFRMTDAFQKLTPGERQQSDATFAQLMVEYFTNEKMYQDALSIILSSLKTVNWQYSMVKSLHRALLAIEDENSAARLLSVVNRKSK\n","tensor([[ 2, 10, 15, 23, 13, 19, 13, 21, 15, 12,  9, 19, 17,  9, 10, 14, 15, 21,\n","         15, 20,  9, 10, 23, 10, 20,  5, 10,  9, 10, 17,  9, 21, 25,  9, 28, 20,\n","         10, 14, 14, 22, 14, 23, 17,  9, 15,  9, 22, 19, 25, 15, 22, 14,  8, 10,\n","         17, 23, 23,  8, 22, 17,  5, 15, 25,  8, 17, 11, 13, 13, 19, 22,  9, 10,\n","         15, 15, 28, 15, 25, 22, 16, 14, 12, 14, 15,  5, 23, 17,  7,  5, 13, 28,\n","          9, 25, 22, 16, 14,  5,  5, 13,  5, 10, 12,  8, 28,  9, 15,  5, 16, 23,\n","         23, 26, 14, 17, 21, 11, 14, 10, 21, 16, 23,  8,  5, 10, 20, 14, 15, 23,\n","         19, 11,  9, 21, 20, 20, 22,  8,  5, 23, 10,  5, 20, 15, 16, 25,  9, 28,\n","         10, 23, 17,  9, 14, 16, 28, 20,  8,  5, 15, 22, 13, 13, 15, 22, 22, 15,\n","         14, 23, 25, 17, 26, 20, 28, 22, 16, 25, 14, 22, 15, 12, 21,  5, 15, 15,\n","          5, 13,  9,  8,  9, 17, 22,  5,  5, 21, 15, 15, 22, 25, 25, 17, 21, 14,\n","         22,  3]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nF4CPx39yAN-","executionInfo":{"status":"ok","timestamp":1610182794297,"user_tz":-300,"elapsed":1299,"user":{"displayName":"Akira Blac","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjahauVm3Xisytr3Mhx327sUBpZk09bRao0fxbHnw=s64","userId":"15395188499654194491"}},"outputId":"c786086a-386d-47af-e368-67012e43f91a"},"source":["print(sequence)\r\n","print(len(sequence))\r\n","print(token_ids)\r\n","print(len(list(token_ids[0])))\r\n","print(sequence_output.shape)\r\n","print(pooled_output.shape)\r\n","# print(pooled_output)\r\n","print(pooled_output[0].tolist())\r\n","# print(type(output[0][0].detach().numpy()))\r\n","print(output[0][0].detach().numpy()[:, :64].shape)\r\n","print(output[0][0].detach().numpy().shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TFLTIPIRLHEPNEFKLRLQEFTFQAFEFNERVEYQFKKSKTNELESPVLSKDFNTTDSNALVDNGIIPSEFLLYLVSMKHKLATNCAIYEVSMKAAIAFHDYELAMTTWKNRGKFRMTDAFQKLTPGERQQSDATFAQLMVEYFTNEKMYQDALSIILSSLKTVNWQYSMVKSLHRALLAIEDENSAARLLSVVNRKSK\n","200\n","tensor([[ 2, 10, 15, 23, 13, 19, 13, 21, 15, 12,  9, 19, 17,  9, 10, 14, 15, 21,\n","         15, 20,  9, 10, 23, 10, 20,  5, 10,  9, 10, 17,  9, 21, 25,  9, 28, 20,\n","         10, 14, 14, 22, 14, 23, 17,  9, 15,  9, 22, 19, 25, 15, 22, 14,  8, 10,\n","         17, 23, 23,  8, 22, 17,  5, 15, 25,  8, 17, 11, 13, 13, 19, 22,  9, 10,\n","         15, 15, 28, 15, 25, 22, 16, 14, 12, 14, 15,  5, 23, 17,  7,  5, 13, 28,\n","          9, 25, 22, 16, 14,  5,  5, 13,  5, 10, 12,  8, 28,  9, 15,  5, 16, 23,\n","         23, 26, 14, 17, 21, 11, 14, 10, 21, 16, 23,  8,  5, 10, 20, 14, 15, 23,\n","         19, 11,  9, 21, 20, 20, 22,  8,  5, 23, 10,  5, 20, 15, 16, 25,  9, 28,\n","         10, 23, 17,  9, 14, 16, 28, 20,  8,  5, 15, 22, 13, 13, 15, 22, 22, 15,\n","         14, 23, 25, 17, 26, 20, 28, 22, 16, 25, 14, 22, 15, 12, 21,  5, 15, 15,\n","          5, 13,  9,  8,  9, 17, 22,  5,  5, 21, 15, 15, 22, 25, 25, 17, 21, 14,\n","         22,  3]])\n","200\n","torch.Size([1, 200, 768])\n","torch.Size([1, 768])\n","[-0.3783828616142273, -0.70220947265625, -0.5801433324813843, -0.37757083773612976, -0.12886305153369904, -0.4716190993785858, -0.3908011019229889, -0.015661299228668213, 0.4835740923881531, 0.8020552396774292, -0.3931855261325836, 0.24828492105007172, 0.060607410967350006, 0.11222995817661285, -0.22158551216125488, 0.6763560175895691, -0.6365146040916443, 0.4671977460384369, -0.6993057131767273, -0.21643145382404327, 0.3914611339569092, 0.31947800517082214, -0.672268271446228, -0.3028331696987152, 0.13768230378627777, -0.3983849287033081, -0.5036793947219849, -0.18314960598945618, -0.09355856478214264, 0.5144048929214478, -0.5976974368095398, -0.38275980949401855, 0.08309134095907211, -0.46784600615501404, -0.23361952602863312, -0.27131083607673645, -0.5879485011100769, -0.5272655487060547, 0.17042940855026245, 0.5239120125770569, -0.1917775273323059, 0.19606705009937286, 0.3886127173900604, -0.1513786017894745, -0.1695854514837265, -0.3006787896156311, 0.24695450067520142, -0.378976047039032, 0.3239035904407501, -0.5039609670639038, 0.4796590507030487, -0.2176060527563095, 0.415780246257782, 0.2117476761341095, 0.7621498107910156, -0.09212660044431686, 0.6484411358833313, 0.3325871229171753, -0.3486694097518921, -0.037909362465143204, -0.5741518139839172, 0.12174982577562332, -0.5044808983802795, -0.5837515592575073, 0.022812774404883385, 0.3928678631782532, -0.11009304970502853, 0.4123009741306305, 0.06230853497982025, 0.33975815773010254, -0.5665987133979797, -0.44714704155921936, 0.14101946353912354, 0.18058213591575623, 0.3725796639919281, -0.08463991433382034, 0.18487633764743805, 0.2028009444475174, 0.17951859533786774, -0.6652886271476746, 0.7446378469467163, 0.3909573256969452, 0.13305871188640594, 0.8335621953010559, -0.4613703787326813, -0.47050175070762634, -0.5749281644821167, 0.1775299310684204, 0.15046092867851257, 0.10467853397130966, 0.4716506004333496, -0.29064837098121643, 0.13326036930084229, -0.3844606280326843, 0.555783748626709, -0.6975879073143005, -0.47588518261909485, -0.6693338751792908, 0.4267789125442505, -0.7159871459007263, -0.12246401607990265, 0.5136209726333618, 0.1446802318096161, -0.09015516191720963, 0.17697842419147491, 0.7397386431694031, 0.3313746750354767, 0.5858814716339111, 0.11856956779956818, 0.11661450564861298, 0.7545225024223328, 0.47682076692581177, -0.21899107098579407, 0.6543127298355103, 0.38175511360168457, 0.42002397775650024, -0.3635150194168091, -0.22358235716819763, 0.3735317885875702, -0.6135265231132507, -0.31193357706069946, -0.09069202095270157, -0.4568648934364319, -0.5083537101745605, -0.6035562753677368, 0.5979840159416199, -0.15336570143699646, -0.8398014903068542, -0.013474155217409134, 0.35136210918426514, 0.255004346370697, -0.028011517599225044, 0.5690367817878723, -0.41969165205955505, -0.2323405146598816, 0.23490656912326813, -0.020917881280183792, 0.48841071128845215, 0.08567699790000916, 0.20379339158535004, 0.6834650635719299, 0.1593841314315796, -0.7616410255432129, 0.12605443596839905, -0.3639366924762726, 0.12916986644268036, -0.39858579635620117, -0.44348961114883423, 0.4002079665660858, -0.20317722856998444, 0.46065205335617065, 0.645140528678894, -0.6366934180259705, -0.016026614233851433, 0.15518033504486084, 0.7888916730880737, -0.4128358066082001, -0.792833685874939, 0.3613351285457611, 0.4941224455833435, -0.5406686663627625, 0.32064759731292725, -0.2569614052772522, 0.24389173090457916, 0.07260297983884811, -0.1145356297492981, 0.5247308015823364, 0.18044579029083252, 0.21703028678894043, 0.18137423694133759, 0.4978949725627899, -0.5520715713500977, -0.875232458114624, 0.6149214506149292, -0.4087303578853607, 0.08181001245975494, 0.052968233823776245, 0.5612200498580933, 0.7293217182159424, 0.31638121604919434, -0.574594259262085, 0.09439662843942642, 0.447408527135849, 0.7450404167175293, -0.1878712922334671, 0.358359158039093, 0.7903192639350891, 0.5832154154777527, -0.5574028491973877, 0.8326655030250549, -0.33791613578796387, -0.3057962656021118, 0.027705594897270203, 0.5617350339889526, 0.23122763633728027, 0.35605189204216003, -0.078803151845932, 0.057640254497528076, 0.43109843134880066, -0.16683223843574524, 0.1588423252105713, 0.4414256811141968, 0.4704466164112091, -0.1980813592672348, 0.37533336877822876, -0.1513773649930954, -0.04800620302557945, -0.3785579800605774, -0.3875270485877991, -0.30126631259918213, 0.4971894919872284, 0.26152533292770386, 0.6219653487205505, -0.14637354016304016, -0.7072792649269104, 0.14264971017837524, -0.389530748128891, -0.25044742226600647, 0.013772104866802692, -0.5372200012207031, 0.3855580687522888, -0.600673496723175, -0.6814380288124084, 0.05687229335308075, -0.6447217464447021, -0.6333242654800415, -0.5837037563323975, 0.3541033864021301, -0.35610872507095337, 0.4134707748889923, -0.44424721598625183, -0.42729872465133667, -0.7427498698234558, -0.6301008462905884, -0.3520132899284363, 0.2724163234233856, -0.05329825356602669, 0.8569890260696411, 0.2802511751651764, -0.33098676800727844, -0.2946971654891968, 0.6208397150039673, -0.4225749373435974, 0.22897721827030182, 0.3256974220275879, 0.1977844536304474, -0.27814123034477234, -0.24942390620708466, -0.43804338574409485, -0.07605094462633133, 0.19598041474819183, 0.17896848917007446, 0.35378697514533997, -0.09828154742717743, -0.4469219446182251, 0.24094653129577637, -0.25987502932548523, 0.4775933027267456, 0.8461146950721741, 0.6015664339065552, 0.20640461146831512, 0.20204421877861023, -0.4414304196834564, 0.5943188667297363, -0.6168346405029297, 0.31246423721313477, 0.5945392847061157, 0.32649317383766174, 0.6827639937400818, -0.4164617955684662, 0.16353839635849, -0.30874842405319214, 0.31531214714050293, -0.18046040832996368, 0.19558769464492798, -0.2689915597438812, 0.38722285628318787, 0.3848029375076294, 0.3589800298213959, -0.6431412100791931, 0.8126523494720459, 0.3131161332130432, 0.025955790653824806, 0.1880221962928772, 0.4836151897907257, -0.35312435030937195, -0.44928857684135437, 0.09261097759008408, 0.5747523307800293, 0.34420549869537354, -0.2398446649312973, 0.0703495517373085, -0.34007206559181213, 0.37237200140953064, -0.03895558416843414, -0.15057498216629028, 0.5836074948310852, -0.6820768713951111, -0.5344275236129761, 0.31991511583328247, 0.40389126539230347, 0.4827153980731964, -0.3196266293525696, -0.4092065095901489, -0.38565945625305176, 0.44332191348075867, 0.07550323009490967, -0.16312210261821747, 0.7071610689163208, -0.2859547734260559, -0.6420340538024902, 0.11685148626565933, 0.05808134749531746, -0.6085917949676514, -0.5701766610145569, 0.3679089844226837, -0.5130106806755066, 0.06124430522322655, -0.6850304007530212, -0.2771630883216858, -0.44882047176361084, 0.38033047318458557, 0.2994139790534973, 0.46439382433891296, 0.37382814288139343, 0.012446267530322075, 0.17110314965248108, -0.155988872051239, -0.5639148354530334, -0.8261256217956543, 0.47791051864624023, 0.5704054236412048, -0.2065882682800293, 0.2733442783355713, 0.4854016602039337, 0.6261193752288818, 0.1867516040802002, -0.6692345142364502, 0.5567730665206909, 0.4042099416255951, 0.491233229637146, 0.7464640140533447, -0.3047376871109009, -0.4512178301811218, -0.6490621566772461, 0.3338588774204254, -0.5668590068817139, -0.20753449201583862, -0.02155413292348385, 0.6427381038665771, 0.5467431545257568, -0.6987947821617126, 0.5545555353164673, 0.3768852949142456, -0.5512112379074097, -0.5167899131774902, -0.6458819508552551, -0.3206383287906647, -0.35628920793533325, -0.6258170008659363, 0.11684796214103699, -0.16357707977294922, 0.415386825799942, -0.2439347207546234, -0.5467963218688965, -0.2657555341720581, -0.2943885922431946, -0.25617703795433044, -0.10626727342605591, 0.48609215021133423, 0.9268758296966553, 0.44862183928489685, -0.6739874482154846, -0.8341615200042725, -0.023252861574292183, -0.5958635210990906, -0.2697758972644806, -0.43500953912734985, 0.0951659083366394, 0.04575797915458679, -0.286190003156662, -0.5954204201698303, 0.6467782258987427, 0.6370903253555298, -0.11113061010837555, 0.7970101833343506, 0.22660861909389496, 0.4806901514530182, 0.10593198239803314, 0.8576679229736328, -0.5727636218070984, -0.3636377155780792, 0.6740188598632812, 0.20904919505119324, 0.17817236483097076, 0.03232473134994507, -0.12603598833084106, -0.5912847518920898, 0.24558694660663605, -0.11218912899494171, 0.6338915824890137, 0.5579109787940979, -0.23273232579231262, -0.3996932804584503, -0.39148566126823425, -0.6111276149749756, -0.6616985201835632, 0.5645854473114014, 0.1212695762515068, 0.4038248062133789, 0.08926209807395935, -0.28489604592323303, 0.3669222891330719, 0.7813493609428406, -0.09634867310523987, -0.433000385761261, -0.627597987651825, -0.08425047993659973, -0.48464882373809814, -0.3383461833000183, -0.038210079073905945, -0.5877025127410889, 0.5771805644035339, -0.11903344839811325, 0.5143487453460693, 0.8843201994895935, -0.30168792605400085, 0.042766932398080826, -0.7178606390953064, 0.5221652388572693, -0.42461520433425903, -0.33161234855651855, -0.6662588119506836, 0.7509179711341858, -0.42093613743782043, 0.21275979280471802, -0.3117619752883911, -0.5830630660057068, 0.015202945098280907, -0.48525673151016235, -0.6081726551055908, 0.5060732960700989, 0.49945515394210815, 0.05724092200398445, 0.7869133949279785, -0.8253554701805115, 0.5200726985931396, -0.27111831307411194, 0.49908652901649475, 0.5310565233230591, 0.08603575080633163, -0.0457051619887352, 0.5839335322380066, -0.5581693649291992, 0.41560280323028564, -0.22296763956546783, 0.17312607169151306, 0.20402826368808746, -0.028374891728162766, 0.030162302777171135, 0.8036385178565979, -0.5419412851333618, 0.574850857257843, -0.052662186324596405, 0.2736154794692993, 0.004434824921190739, -0.20968125760555267, -0.14432431757450104, -0.16713905334472656, 0.35005873441696167, 0.08992236107587814, 0.46982383728027344, 0.5168474912643433, -0.5778969526290894, -0.4050137400627136, -0.4514646828174591, 0.587051510810852, -0.40312647819519043, 0.011953872628509998, 0.3006570041179657, 0.7479413151741028, -0.24484801292419434, 0.3862636089324951, -0.25916433334350586, 0.3312079608440399, -0.3629293143749237, -0.3953263461589813, -0.15049423277378082, 0.6736152172088623, -0.41947731375694275, -0.3779919147491455, 0.7444380521774292, 0.010392649099230766, 0.5690871477127075, -0.3332058787345886, 0.028305478394031525, -0.44852253794670105, -0.4828526973724365, -0.6359332799911499, -0.5243211984634399, -0.14930008351802826, -0.4640923738479614, 0.4587072730064392, -0.7867436408996582, 0.31423166394233704, -0.5481526851654053, 0.5336713790893555, -0.3280804455280304, -0.22482365369796753, -0.5399357080459595, 0.3165113031864166, -0.28354552388191223, -0.8002890348434448, -0.3714652955532074, 0.0787632018327713, 0.1893063634634018, -0.6747593283653259, 0.790510892868042, 0.11023645102977753, -0.7180625200271606, 0.35880160331726074, -0.3630269467830658, 0.6620594263076782, 0.12369021028280258, 0.7279332876205444, -0.4785442650318146, -0.866658091545105, -0.004103607963770628, -0.37484264373779297, 0.3477504551410675, 0.03231797367334366, -0.21166841685771942, 0.5272327065467834, 0.283678263425827, -0.6821353435516357, -0.13458223640918732, -0.48006683588027954, 0.4670412838459015, -0.4807193875312805, -0.816580593585968, -0.5541508197784424, -0.25921204686164856, -0.5032103061676025, -0.821158230304718, -0.1495618224143982, 0.41443657875061035, -0.13184238970279694, 0.8624085187911987, -0.49579793214797974, -0.1450689285993576, -0.2169276475906372, 0.3972877562046051, -0.5129169225692749, 0.20758949220180511, -0.12881186604499817, -0.8812220692634583, 0.445901483297348, -0.4887237846851349, 0.9018092751502991, -0.49352338910102844, 0.1853269785642624, 0.683077871799469, -0.14941546320915222, 0.10400841385126114, -0.2185029834508896, 0.4985869824886322, -0.023050427436828613, -0.03375434875488281, 0.46582797169685364, -0.22393609583377838, 0.3729187548160553, 0.20750005543231964, 0.18374492228031158, -0.4004036486148834, -0.09437886625528336, 0.5241256952285767, 0.6509304642677307, -0.27496108412742615, -0.12523703277111053, -0.721322774887085, 0.6680130362510681, -0.8526299595832825, 0.7590426206588745, 0.23097696900367737, -0.6765702962875366, -0.4844226837158203, 0.0764063149690628, -0.08176986128091812, 0.44036877155303955, -0.36989474296569824, -0.3202016353607178, -0.15583017468452454, 0.48993104696273804, 0.15871474146842957, -0.006055981386452913, -0.6738893985748291, 0.5059396028518677, -0.0680270567536354, -0.268303245306015, 0.6303498148918152, -0.25728926062583923, 0.16042211651802063, 0.34253033995628357, -0.7042229175567627, 0.15452612936496735, 0.1438811719417572, -0.005224493332207203, 0.6677407622337341, 0.6544277667999268, -0.2545590102672577, -0.48864540457725525, 0.14751695096492767, -0.03766462579369545, -0.04019812494516373, 0.10693909227848053, -0.6831433773040771, -0.43323758244514465, 0.3255714178085327, -0.23864242434501648, 0.37966880202293396, -0.37046581506729126, -0.6568775177001953, -0.25931861996650696, -0.22880956530570984, -0.5281160473823547, -0.2011069506406784, -0.4913763403892517, -0.15446588397026062, 0.6757796406745911, 0.6282574534416199, 0.6456819176673889, 0.5569168925285339, 0.0437321811914444, -0.2394559532403946, 0.4296702444553375, -0.02888561226427555, -0.15392038226127625, -0.3145969808101654, -0.7267164587974548, 0.1153377965092659, 0.20524096488952637, -0.07219410687685013, 0.4043560326099396, 0.2961672246456146, 0.5569736361503601, 0.47417929768562317, -0.731761634349823, 0.6438767910003662, -0.30879005789756775, -0.35187482833862305, -0.3163062036037445, -0.3226259648799896, -0.08241573721170425, -0.27908384799957275, 0.7374007701873779, 0.2971159517765045, -0.34650465846061707, -0.3177225589752197, 0.47137174010276794, 0.3289387822151184, -0.3140896260738373, -0.1630111038684845, 0.7291455864906311, 0.0851438045501709, 0.3137896955013275, 0.5612640976905823, -0.3389873802661896, -0.10395940393209457, 0.03291427716612816, -0.5083765983581543, 0.09046701341867447, -0.5075604319572449, -0.3110122084617615, -0.6177221536636353, -0.57472825050354, -0.34348076581954956, 0.7937524318695068, 0.11071647703647614, -0.4773632287979126, 0.5415583252906799, 0.13436724245548248, -0.1029169112443924, -0.04918123781681061, -0.2067088782787323, -0.10790704935789108, 0.6252626776695251, 0.5284721851348877, -0.2585090398788452, 0.19448155164718628, 0.07913598418235779, 0.34670740365982056, 0.58636075258255, -0.3893253207206726, 0.5313565731048584, -0.18342573940753937, 0.04948005825281143, -0.2643485963344574, -0.10129471123218536, -0.25490567088127136, 0.21665573120117188, -0.6874442100524902, 0.6238468885421753, 0.4737735390663147, 0.18481312692165375, 0.7940113544464111, 0.575664222240448, -0.0038926703855395317, 0.20776696503162384, -0.6110468506813049, -0.41996055841445923, 0.1596817970275879, 0.2073405385017395, -0.7458630800247192, 0.4201442003250122, 0.18213710188865662, -0.12815852463245392, -0.2594802975654602, -0.6383338570594788, 0.288166880607605, 0.5387952923774719, -0.36313584446907043, 0.20226898789405823, -0.2490072399377823, 0.5650202035903931, 0.4269985258579254, 0.4192023277282715, 0.2538028061389923, 0.34998252987861633, 0.1180146336555481, -0.14714385569095612, 0.34037789702415466, -0.4205459952354431, 0.3260914981365204, 0.17500752210617065, 0.9089329838752747, -0.3076011538505554, -0.23784776031970978, -0.0967739149928093, 0.04895168915390968, 0.3422728478908539, 0.1669663041830063, -0.5390405058860779, -0.7251536250114441, -0.6035977602005005, 0.7047337293624878, -0.5593408942222595, 0.058611299842596054, -0.07984446734189987, -0.12068119645118713, 0.5546172857284546, -0.18693295121192932, -0.3696717619895935, -0.42009931802749634, -0.22645807266235352, 0.43929359316825867, 0.32470330595970154, 0.364017128944397, 0.17275260388851166, -0.731308102607727, -0.285433292388916, 0.15719780325889587, 0.2989535927772522, 0.6876205801963806, -0.025835426524281502, 0.08947110176086426, 0.033210813999176025, 0.8035215735435486, -0.7456974387168884]\n","(200, 64)\n","(200, 768)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dJa3UVW3tIU0"},"source":["def convert_input_to_TapeBertPoolingOutput(sequence, tokenizer, model):\r\n","  max_sequence_length = len(sequence)\r\n","  seq_wo_dash = sequence[:len(sequence) if sequence.find(\"-\") == -1 else sequence.find(\"-\")]\r\n","  if max_sequence_length == len(seq_wo_dash):\r\n","    token_ids = torch.tensor([tokenizer.encode(seq_wo_dash[1:-1])])\r\n","  else:\r\n","    token_ids = torch.tensor([np.append(tokenizer.encode(seq_wo_dash), [0]*(max_sequence_length-len(seq_wo_dash)-2))], dtype=int)\r\n","  \r\n","  output = model(token_ids)\r\n","  # sequence_output = output[0]\r\n","  # pooled_output = output[1]\r\n","\r\n","  return output[1][0].tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7KoosN44tOG1"},"source":["def convert_input_to_TapeBertEmbedding(sequence, tokenizer, model):\r\n","  max_sequence_length = len(sequence)\r\n","  seq_wo_dash = sequence[:len(sequence) if sequence.find(\"-\") == -1 else sequence.find(\"-\")]\r\n","  if max_sequence_length == len(seq_wo_dash):\r\n","    token_ids = torch.tensor([tokenizer.encode(seq_wo_dash[1:-1])])\r\n","  else:\r\n","    token_ids = torch.tensor([np.append(tokenizer.encode(seq_wo_dash), [0]*(max_sequence_length-len(seq_wo_dash)-2))], dtype=int)\r\n","  \r\n","  output = model(token_ids)\r\n","  # sequence_output = output[0]\r\n","  # pooled_output = output[1]\r\n","\r\n","  return output[0][0].detach().numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["14e0bc9ca8224f9b89114a49f36f9c0c","d24b2787c84942f5afd180ae44105151","5ddbf6453431410991bd6787576e0be5","01d8ce4a34ab48ed9f483d400dedb386","385a3ba9fdc34eda8fd7114a9108e2ee","645ee73dd87f4539a8d7afa819c50718","80c8e0a303094066a6911c7e42aa1f8c","d533b75a00dc4629a3d46d8d57163b0d"]},"id":"hZjWdPMU7TjM","outputId":"93971ace-17ba-44e1-c343-a83db59d9c37"},"source":["inputX = []\r\n","if os.path.exists(\"bert_thesis_experiments/tape_protein_files/train_seq_bert_iupac_tape_embedding.npy\"):\r\n","  inputX = np.load(\"bert_thesis_experiments/tape_protein_files/train_seq_bert_iupac_tape_embedding.npy\")\r\n","else:\r\n","  for i in tqdm(rawdata, ncols=\"600px\"):\r\n","    inputX.append(convert_input_to_TapeBertEmbedding(i[0], tokenizer, model))\r\n","  # inputX = [convert_input_to_TapeBertPoolingOutput(i[0], tokenizer, model) for i in rawdata]\r\n","\r\n","  np.save('bert_thesis_experiments/tape_protein_files/train_seq_bert_iupac_tape_embedding.npy', inputX)\r\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"14e0bc9ca8224f9b89114a49f36f9c0c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=31400.0), HTML(value='')), layout=Layout(…"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"fWSo9vcTZX2k"},"source":["print(np.array(inputX).shape)\r\n","# print(np.array(inputX[0]).reshape(-1,768).shape)\r\n","# np.array(inputX[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wNXG7CT3Kqq4"},"source":["if os.path.exists(\"bert_thesis_experiments/tape_protein_files/train_label_bert_iupac_tape_embedding.npy\"):\r\n","  inputY = np.load(\"bert_thesis_experiments/tape_protein_files/train_label_bert_iupac_tape_embedding.npy\")\r\n","else:\r\n","  # inputY = [utils.convertlabels_to_binary(i[1]) for i in rawdata]\r\n","  inputY = [utils.convertlabels_to_categorical(i[1]) for i in rawdata]\r\n","  np.save('bert_thesis_experiments/tape_protein_files/train_label_bert_iupac_tape_embedding.npy', inputY)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C--ucNROg6je"},"source":["print(np.array(inputY).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H4pM6Fkv-mdp"},"source":["def get_train_X_Y_Val_ffnn_tape_pool(inputX, inputY):\r\n","  data=list(zip(inputX,inputY))\r\n","  random.seed(4)\r\n","  random.shuffle(data)\r\n","  random.shuffle(data)\r\n","      \r\n","  train_num=int(len(inputX)*0.9)\r\n","  train=data[0:train_num]\r\n","  val=data[train_num:]\r\n","\r\n","  trainX=np.array([i[0] for i in train])\r\n","  trainY=np.array([i[1] for i in train])\r\n","  # xx=np.dstack(trainX)\r\n","  # xx=np.rollaxis(xx,-1)\r\n","\r\n","  print(trainX.shape)   \r\n","  print(trainY.shape) \r\n","\r\n","  # yy=np.dstack(trainY)\r\n","  # yy=np.rollaxis(yy,-1)\r\n","\r\n","  # print(yy.shape)\r\n","      \r\n","  valX=np.array([i[0] for i in val])\r\n","  valY=np.array([i[1] for i in val])\r\n","  # valX=np.dstack(valX)\r\n","  # valX=np.rollaxis(valX,-1)\r\n","\r\n","  # valY=np.dstack(valY)\r\n","  # valY=np.rollaxis(valY,-1)\r\n","\r\n","  vv=(valX,valY)\r\n","\r\n","  print(\"\\n---Validation Data---\")\r\n","  print(valX.shape)\r\n","  print(valY.shape)\r\n","\r\n","  return trainX, trainY, vv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QBr2sl7W-76F","executionInfo":{"status":"ok","timestamp":1607936601531,"user_tz":-300,"elapsed":14499,"user":{"displayName":"Akira Blac","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjahauVm3Xisytr3Mhx327sUBpZk09bRao0fxbHnw=s64","userId":"15395188499654194491"}},"outputId":"4221d216-1957-4598-83ad-758e12b0bcc5"},"source":["trainX, trainY, vv = get_train_X_Y_Val_ffnn_tape_pool(inputX, inputY)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(28260, 768)\n","(28260, 200)\n","\n","---Validation Data---\n","(3140, 768)\n","(3140, 200)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fsq5nmG9RQJ1"},"source":["def create_model_tape_ffnn_pool(input_dim, classes):\r\n","  model = keras.models.Sequential()\r\n","\r\n","  model.add(keras.layers.Dense(units=1500, input_dim=input_dim))\r\n","  model.add(keras.layers.Activation(\"relu\"))\r\n","  model.add(keras.layers.Dropout(0.5))\r\n","\r\n","  for i in range(0,3):\r\n","      model.add(keras.layers.Dense(units=1500, input_dim=1500))\r\n","      model.add(keras.layers.Activation(\"relu\"))\r\n","  model.add(keras.layers.Dropout(0.5))\r\n","\r\n","  model.add(keras.layers.Dense(units=classes, input_dim=1500))\r\n","  model.add(keras.layers.Activation(\"sigmoid\"))\r\n","\r\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"62k1_Hu2868a"},"source":["model = create_model_tape_ffnn_pool(768, seq_length)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eg4O0Pqj9Zkb","executionInfo":{"status":"ok","timestamp":1607936602102,"user_tz":-300,"elapsed":15054,"user":{"displayName":"Akira Blac","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjahauVm3Xisytr3Mhx327sUBpZk09bRao0fxbHnw=s64","userId":"15395188499654194491"}},"outputId":"1344dbb4-30e0-461b-c26d-b95e938b8768"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 1500)              1153500   \n","_________________________________________________________________\n","activation (Activation)      (None, 1500)              0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 1500)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1500)              2251500   \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 1500)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1500)              2251500   \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 1500)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1500)              2251500   \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 1500)              0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 1500)              0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 200)               300200    \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 200)               0         \n","=================================================================\n","Total params: 8,208,200\n","Trainable params: 8,208,200\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"WVRAhw9Q-Nmr","executionInfo":{"status":"error","timestamp":1607936698178,"user_tz":-300,"elapsed":111123,"user":{"displayName":"Akira Blac","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjahauVm3Xisytr3Mhx327sUBpZk09bRao0fxbHnw=s64","userId":"15395188499654194491"}},"outputId":"a554e5a7-2a4c-4e82-9b86-5188edb9c5a7"},"source":["early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\r\n","\r\n","# model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(lr=0.01), metrics=[\"binary_accuracy\"])\r\n","model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adadelta(lr=.01), metrics=['binary_accuracy'])\r\n","\r\n","fitHistory_batch = model.fit(x=trainX, y=trainY, validation_data=vv, epochs=300, batch_size=128, verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.6635 - binary_accuracy: 0.6138 - val_loss: 0.6208 - val_binary_accuracy: 0.7723\n","Epoch 2/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.5733 - binary_accuracy: 0.7547 - val_loss: 0.5097 - val_binary_accuracy: 0.8158\n","Epoch 3/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.5108 - binary_accuracy: 0.8046 - val_loss: 0.4780 - val_binary_accuracy: 0.8191\n","Epoch 4/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4991 - binary_accuracy: 0.8138 - val_loss: 0.4745 - val_binary_accuracy: 0.8191\n","Epoch 5/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4950 - binary_accuracy: 0.8162 - val_loss: 0.4736 - val_binary_accuracy: 0.8191\n","Epoch 6/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4926 - binary_accuracy: 0.8174 - val_loss: 0.4734 - val_binary_accuracy: 0.8191\n","Epoch 7/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4912 - binary_accuracy: 0.8180 - val_loss: 0.4732 - val_binary_accuracy: 0.8191\n","Epoch 8/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4896 - binary_accuracy: 0.8185 - val_loss: 0.4730 - val_binary_accuracy: 0.8191\n","Epoch 9/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4885 - binary_accuracy: 0.8188 - val_loss: 0.4731 - val_binary_accuracy: 0.8191\n","Epoch 10/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4875 - binary_accuracy: 0.8191 - val_loss: 0.4731 - val_binary_accuracy: 0.8191\n","Epoch 11/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4868 - binary_accuracy: 0.8192 - val_loss: 0.4731 - val_binary_accuracy: 0.8191\n","Epoch 12/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4860 - binary_accuracy: 0.8193 - val_loss: 0.4734 - val_binary_accuracy: 0.8191\n","Epoch 13/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4856 - binary_accuracy: 0.8194 - val_loss: 0.4730 - val_binary_accuracy: 0.8191\n","Epoch 14/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4849 - binary_accuracy: 0.8195 - val_loss: 0.4730 - val_binary_accuracy: 0.8191\n","Epoch 15/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4843 - binary_accuracy: 0.8196 - val_loss: 0.4733 - val_binary_accuracy: 0.8191\n","Epoch 16/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4840 - binary_accuracy: 0.8196 - val_loss: 0.4732 - val_binary_accuracy: 0.8191\n","Epoch 17/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4837 - binary_accuracy: 0.8197 - val_loss: 0.4731 - val_binary_accuracy: 0.8191\n","Epoch 18/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4828 - binary_accuracy: 0.8197 - val_loss: 0.4731 - val_binary_accuracy: 0.8191\n","Epoch 19/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4826 - binary_accuracy: 0.8197 - val_loss: 0.4730 - val_binary_accuracy: 0.8191\n","Epoch 20/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4824 - binary_accuracy: 0.8198 - val_loss: 0.4730 - val_binary_accuracy: 0.8191\n","Epoch 21/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4822 - binary_accuracy: 0.8198 - val_loss: 0.4731 - val_binary_accuracy: 0.8191\n","Epoch 22/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4820 - binary_accuracy: 0.8198 - val_loss: 0.4730 - val_binary_accuracy: 0.8191\n","Epoch 23/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4814 - binary_accuracy: 0.8198 - val_loss: 0.4731 - val_binary_accuracy: 0.8191\n","Epoch 24/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4814 - binary_accuracy: 0.8198 - val_loss: 0.4730 - val_binary_accuracy: 0.8191\n","Epoch 25/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4813 - binary_accuracy: 0.8198 - val_loss: 0.4731 - val_binary_accuracy: 0.8191\n","Epoch 26/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4811 - binary_accuracy: 0.8198 - val_loss: 0.4731 - val_binary_accuracy: 0.8191\n","Epoch 27/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4806 - binary_accuracy: 0.8198 - val_loss: 0.4729 - val_binary_accuracy: 0.8191\n","Epoch 28/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4806 - binary_accuracy: 0.8199 - val_loss: 0.4733 - val_binary_accuracy: 0.8191\n","Epoch 29/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4803 - binary_accuracy: 0.8199 - val_loss: 0.4733 - val_binary_accuracy: 0.8191\n","Epoch 30/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4800 - binary_accuracy: 0.8199 - val_loss: 0.4731 - val_binary_accuracy: 0.8191\n","Epoch 31/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4801 - binary_accuracy: 0.8199 - val_loss: 0.4733 - val_binary_accuracy: 0.8191\n","Epoch 32/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4799 - binary_accuracy: 0.8199 - val_loss: 0.4730 - val_binary_accuracy: 0.8191\n","Epoch 33/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4797 - binary_accuracy: 0.8199 - val_loss: 0.4732 - val_binary_accuracy: 0.8191\n","Epoch 34/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4794 - binary_accuracy: 0.8199 - val_loss: 0.4733 - val_binary_accuracy: 0.8191\n","Epoch 35/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4792 - binary_accuracy: 0.8199 - val_loss: 0.4733 - val_binary_accuracy: 0.8191\n","Epoch 36/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4791 - binary_accuracy: 0.8199 - val_loss: 0.4731 - val_binary_accuracy: 0.8191\n","Epoch 37/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4790 - binary_accuracy: 0.8199 - val_loss: 0.4733 - val_binary_accuracy: 0.8191\n","Epoch 38/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4793 - binary_accuracy: 0.8199 - val_loss: 0.4733 - val_binary_accuracy: 0.8191\n","Epoch 39/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4789 - binary_accuracy: 0.8199 - val_loss: 0.4734 - val_binary_accuracy: 0.8191\n","Epoch 40/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4788 - binary_accuracy: 0.8199 - val_loss: 0.4729 - val_binary_accuracy: 0.8191\n","Epoch 41/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4786 - binary_accuracy: 0.8199 - val_loss: 0.4732 - val_binary_accuracy: 0.8191\n","Epoch 42/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4786 - binary_accuracy: 0.8199 - val_loss: 0.4730 - val_binary_accuracy: 0.8191\n","Epoch 43/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.4783 - binary_accuracy: 0.8199 - val_loss: 0.4731 - val_binary_accuracy: 0.8191\n","Epoch 44/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4781 - binary_accuracy: 0.8199 - val_loss: 0.4731 - val_binary_accuracy: 0.8191\n","Epoch 45/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4781 - binary_accuracy: 0.8199 - val_loss: 0.4733 - val_binary_accuracy: 0.8191\n","Epoch 46/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4779 - binary_accuracy: 0.8199 - val_loss: 0.4730 - val_binary_accuracy: 0.8191\n","Epoch 47/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.4779 - binary_accuracy: 0.8199 - val_loss: 0.4731 - val_binary_accuracy: 0.8191\n","Epoch 48/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4779 - binary_accuracy: 0.8199 - val_loss: 0.4734 - val_binary_accuracy: 0.8191\n","Epoch 49/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4778 - binary_accuracy: 0.8199 - val_loss: 0.4734 - val_binary_accuracy: 0.8191\n","Epoch 50/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4781 - binary_accuracy: 0.8199 - val_loss: 0.4733 - val_binary_accuracy: 0.8191\n","Epoch 51/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4776 - binary_accuracy: 0.8199 - val_loss: 0.4732 - val_binary_accuracy: 0.8191\n","Epoch 52/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4776 - binary_accuracy: 0.8199 - val_loss: 0.4734 - val_binary_accuracy: 0.8191\n","Epoch 53/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4777 - binary_accuracy: 0.8199 - val_loss: 0.4734 - val_binary_accuracy: 0.8191\n","Epoch 54/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4774 - binary_accuracy: 0.8199 - val_loss: 0.4734 - val_binary_accuracy: 0.8191\n","Epoch 55/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4776 - binary_accuracy: 0.8199 - val_loss: 0.4736 - val_binary_accuracy: 0.8191\n","Epoch 56/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4775 - binary_accuracy: 0.8199 - val_loss: 0.4736 - val_binary_accuracy: 0.8191\n","Epoch 57/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.4773 - binary_accuracy: 0.8199 - val_loss: 0.4733 - val_binary_accuracy: 0.8191\n","Epoch 58/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4772 - binary_accuracy: 0.8199 - val_loss: 0.4736 - val_binary_accuracy: 0.8191\n","Epoch 59/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.4769 - binary_accuracy: 0.8199 - val_loss: 0.4734 - val_binary_accuracy: 0.8191\n","Epoch 60/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4771 - binary_accuracy: 0.8199 - val_loss: 0.4735 - val_binary_accuracy: 0.8191\n","Epoch 61/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.4770 - binary_accuracy: 0.8199 - val_loss: 0.4733 - val_binary_accuracy: 0.8191\n","Epoch 62/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4768 - binary_accuracy: 0.8199 - val_loss: 0.4734 - val_binary_accuracy: 0.8191\n","Epoch 63/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4769 - binary_accuracy: 0.8199 - val_loss: 0.4736 - val_binary_accuracy: 0.8191\n","Epoch 64/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4768 - binary_accuracy: 0.8199 - val_loss: 0.4734 - val_binary_accuracy: 0.8191\n","Epoch 65/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4769 - binary_accuracy: 0.8199 - val_loss: 0.4735 - val_binary_accuracy: 0.8191\n","Epoch 66/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4768 - binary_accuracy: 0.8199 - val_loss: 0.4737 - val_binary_accuracy: 0.8191\n","Epoch 67/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.4764 - binary_accuracy: 0.8199 - val_loss: 0.4734 - val_binary_accuracy: 0.8191\n","Epoch 68/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4766 - binary_accuracy: 0.8199 - val_loss: 0.4731 - val_binary_accuracy: 0.8191\n","Epoch 69/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.4765 - binary_accuracy: 0.8199 - val_loss: 0.4736 - val_binary_accuracy: 0.8191\n","Epoch 70/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4762 - binary_accuracy: 0.8199 - val_loss: 0.4735 - val_binary_accuracy: 0.8191\n","Epoch 71/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.4765 - binary_accuracy: 0.8199 - val_loss: 0.4733 - val_binary_accuracy: 0.8191\n","Epoch 72/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4763 - binary_accuracy: 0.8199 - val_loss: 0.4734 - val_binary_accuracy: 0.8191\n","Epoch 73/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4764 - binary_accuracy: 0.8199 - val_loss: 0.4736 - val_binary_accuracy: 0.8191\n","Epoch 74/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4763 - binary_accuracy: 0.8199 - val_loss: 0.4735 - val_binary_accuracy: 0.8191\n","Epoch 75/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4761 - binary_accuracy: 0.8199 - val_loss: 0.4735 - val_binary_accuracy: 0.8191\n","Epoch 76/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4762 - binary_accuracy: 0.8199 - val_loss: 0.4733 - val_binary_accuracy: 0.8191\n","Epoch 77/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4759 - binary_accuracy: 0.8199 - val_loss: 0.4735 - val_binary_accuracy: 0.8191\n","Epoch 78/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4760 - binary_accuracy: 0.8199 - val_loss: 0.4736 - val_binary_accuracy: 0.8191\n","Epoch 79/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4762 - binary_accuracy: 0.8199 - val_loss: 0.4736 - val_binary_accuracy: 0.8191\n","Epoch 80/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.4758 - binary_accuracy: 0.8199 - val_loss: 0.4736 - val_binary_accuracy: 0.8191\n","Epoch 81/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4762 - binary_accuracy: 0.8199 - val_loss: 0.4736 - val_binary_accuracy: 0.8191\n","Epoch 82/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.4758 - binary_accuracy: 0.8199 - val_loss: 0.4737 - val_binary_accuracy: 0.8191\n","Epoch 83/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.4758 - binary_accuracy: 0.8199 - val_loss: 0.4737 - val_binary_accuracy: 0.8191\n","Epoch 84/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.4761 - binary_accuracy: 0.8199 - val_loss: 0.4734 - val_binary_accuracy: 0.8191\n","Epoch 85/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.4758 - binary_accuracy: 0.8199 - val_loss: 0.4741 - val_binary_accuracy: 0.8191\n","Epoch 86/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.4757 - binary_accuracy: 0.8199 - val_loss: 0.4737 - val_binary_accuracy: 0.8191\n","Epoch 87/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.4756 - binary_accuracy: 0.8199 - val_loss: 0.4738 - val_binary_accuracy: 0.8191\n","Epoch 88/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.4757 - binary_accuracy: 0.8199 - val_loss: 0.4739 - val_binary_accuracy: 0.8191\n","Epoch 89/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.4755 - binary_accuracy: 0.8199 - val_loss: 0.4738 - val_binary_accuracy: 0.8191\n","Epoch 90/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.4758 - binary_accuracy: 0.8199 - val_loss: 0.4737 - val_binary_accuracy: 0.8191\n","Epoch 91/300\n","221/221 [==============================] - 1s 4ms/step - loss: 0.4757 - binary_accuracy: 0.8199 - val_loss: 0.4739 - val_binary_accuracy: 0.8191\n","Epoch 92/300\n","221/221 [==============================] - 1s 5ms/step - loss: 0.4754 - binary_accuracy: 0.8199 - val_loss: 0.4742 - val_binary_accuracy: 0.8191\n","Epoch 93/300\n","103/221 [============>.................] - ETA: 0s - loss: 0.4754 - binary_accuracy: 0.8198"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-e84d0b1b9d64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdadelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binary_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfitHistory_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"kRWbLVEW_2P_"},"source":[""],"execution_count":null,"outputs":[]}]}