{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT TF Fine-Tuning with TF2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"11Zb2JTfBOzNguEJHgqFuvDISidC0yWjH","authorship_tag":"ABX9TyOOZKMOCcK9MNERGxGkaFPP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ZvibchgxZnF","executionInfo":{"status":"ok","timestamp":1609880175033,"user_tz":-300,"elapsed":3310,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}},"outputId":"dd04d1db-c6fa-402c-c414-d806fa12fd45"},"source":["import tensorflow as tf\r\n","\r\n","# Get the GPU device name.\r\n","device_name = tf.test.gpu_device_name()\r\n","\r\n","# The device name should look like the following:\r\n","if device_name == '/device:GPU:0':\r\n","    print('Found GPU at: {}'.format(device_name))\r\n","else:\r\n","    raise SystemError('GPU device not found')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ci6AC-Yiz-42","executionInfo":{"status":"ok","timestamp":1609880175040,"user_tz":-300,"elapsed":3300,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}},"outputId":"2b32f931-373d-4d32-9e50-0b3df2949b72"},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Tue Jan  5 20:56:15 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   63C    P0    29W /  70W |    227MiB / 15079MiB |      6%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QNSGkWUK0MEI","executionInfo":{"status":"ok","timestamp":1609880177226,"user_tz":-300,"elapsed":3164,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}}},"source":["!pip install -q transformers"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"_TKkXxV48bWI","executionInfo":{"status":"ok","timestamp":1609880185910,"user_tz":-300,"elapsed":6,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}}},"source":["!pip install bert-for-tf2 >> /dev/null"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"siLsPEPm9D3n","executionInfo":{"status":"ok","timestamp":1609880371661,"user_tz":-300,"elapsed":983,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}}},"source":["import numpy as np\r\n","import os\r\n","import random\r\n","\r\n","import bert\r\n","from bert.tokenization.bert_tokenization import FullTokenizer"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bQ9h_Gfl0ax2","executionInfo":{"status":"ok","timestamp":1609880189529,"user_tz":-300,"elapsed":953,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}},"outputId":"5c7897fe-81b7-4d2b-ec17-91166da6275d"},"source":["cd /content/drive/MyDrive/Colab Notebooks"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aXP1Dm8w0fQV","executionInfo":{"status":"ok","timestamp":1609880192093,"user_tz":-300,"elapsed":1412,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}}},"source":["import bert_thesis_experiments.utils as utils"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"uHwEWbYJ1sNx","executionInfo":{"status":"ok","timestamp":1609880192094,"user_tz":-300,"elapsed":569,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}}},"source":["seqfile = 'DeepDom_Code/DeepDom-master/processed_seq.txt'; #file name of the processed sequence data (output from dataprocess.pl)\r\n","labelfile= 'DeepDom_Code/DeepDom-master/processed_label.txt'; #file name of the processed label data (output from dataprocess.pl)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"fNY6r6Ar1vGr","executionInfo":{"status":"ok","timestamp":1609880193393,"user_tz":-300,"elapsed":894,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}}},"source":["(ids,seqs) = utils.process_inputseqs(seqfile)\r\n","(ids,labels) = utils.process_inputlabels(labelfile)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"hvqBDzKaEBUe","executionInfo":{"status":"ok","timestamp":1609880195219,"user_tz":-300,"elapsed":939,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}}},"source":["rawdata = list(zip(seqs,labels))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"aA5xddcW16Ie","executionInfo":{"status":"ok","timestamp":1609880212219,"user_tz":-300,"elapsed":941,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}}},"source":["from transformers import BertTokenizer\r\n","import os\r\n","\r\n","tokenizer = FullTokenizer(vocab_file=os.path.join(\"bert_thesis_experiments/working/\", \"protein_seq_words_uniref0.5_vsz30k_mfq2-vocab.txt\"))\r\n","# tokenizer2 = BertTokenizer.from_pretrained(os.path.join(\"bert_thesis_experiments/working/\", \"protein_seq_words_uniref0.5_vsz30k_mfq2-vocab.txt\"))"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hez7OJuv7F_V","executionInfo":{"status":"ok","timestamp":1609874542127,"user_tz":-300,"elapsed":1019,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}},"outputId":"0463d433-94d9-49fb-f9cf-15dcb9a7dafc"},"source":["vocabulary = tokenizer2.get_vocab()\r\n","\r\n","print(list(vocabulary.keys())[5000:5020])"],"execution_count":21,"outputs":[{"output_type":"stream","text":["['##qral', '##hhy', '##kskk', '##wgf', '##vlkl', '##dlii', '##ekss', '##flee', '##stgv', '##eiar', '##dvdv', '##adtv', '##tiee', '##ahw', '##qill', '##new', '##ilee', '##ilag', '##aegg', '##adsv']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MzeiFWuI5hdA","executionInfo":{"status":"ok","timestamp":1609874547234,"user_tz":-300,"elapsed":1357,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}},"outputId":"508cdf50-f345-434a-bf2e-8d4d660e6900"},"source":["max_length_test = 200\r\n","test_sentence = 'LAHVPNASLINFTDVGTSVSKLLQDYSEIVLMSDEIQQTTDKDDPFLDIVPKFMGTILLILKNLQTKFLETEKYLFETIDYFNPTNQTLQQYQQQQYQQYQQQQFQQNIINNNNNNNNNNSNNNNNNISGNTTTTTTTTTTTTTGSIINNNNNNNNNNNNSNNNIINNNNSQSNLQSLLHPQYYLSNSSSSSSSSYKITP'\r\n","print(\"Sequence:\", test_sentence)\r\n","# add special tokens\r\n","\r\n","test_sentence_with_special_tokens = '[CLS]' + test_sentence + '[SEP]'\r\n","\r\n","tokenized = tokenizer.tokenize(test_sentence)\r\n","\r\n","print('tokenized', tokenized)\r\n","print(\"No. of Tokens:\", len(tokenized))\r\n","# convert tokens to ids in WordPiece\r\n","input_ids = tokenizer.convert_tokens_to_ids([\"[CLS]\"] + tokenized + [\"[SEP]\"])\r\n","  \r\n","# precalculation of pad length, so that we can reuse it later on\r\n","padding_length = max_length_test - len(input_ids)\r\n","\r\n","# map tokens to WordPiece dictionary and add pad token for those text shorter than our max length\r\n","input_ids = input_ids + ([0] * padding_length)\r\n","\r\n","# attention should focus just on sequence with non padded tokens\r\n","attention_mask = [1] * len(input_ids)\r\n","\r\n","# do not focus attention on padded tokens\r\n","attention_mask = attention_mask + ([0] * padding_length)\r\n","\r\n","# token types, needed for example for question answering, for our purpose we will just set 0 as we have just one sequence\r\n","token_type_ids = [0] * max_length_test\r\n","\r\n","bert_input = {\r\n","    \"token_ids\": input_ids,\r\n","    \"token_type_ids\": token_type_ids,\r\n","    \"attention_mask\": attention_mask\r\n","}\r\n","print(bert_input)\r\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Sequence: LAHVPNASLINFTDVGTSVSKLLQDYSEIVLMSDEIQQTTDKDDPFLDIVPKFMGTILLILKNLQTKFLETEKYLFETIDYFNPTNQTLQQYQQQQYQQYQQQQFQQNIINNNNNNNNNNSNNNNNNISGNTTTTTTTTTTTTTGSIINNNNNNNNNNNNSNNNIINNNNSQSNLQSLLHPQYYLSNSSSSSSSSYKITP\n","tokenized ['l', '##ahvp', '##n', '##asli', '##nf', '##td', '##vgt', '##svsk', '##llq', '##dy', '##seiv', '##l', '##m', '##sdei', '##qqtt', '##dkdd', '##pf', '##l', '##divp', '##kfm', '##gt', '##il', '##l', '##ilkn', '##l', '##qtk', '##flet', '##ekyl', '##feti', '##dy', '##fn', '##ptn', '##qtlq', '##qy', '##qqqq', '##yq', '##qy', '##qqqq', '##fq', '##qn', '##iinn', '##nnnnnnnn', '##snnnnnn', '##is', '##gn', '##tttttttt', '##ttttt', '##g', '##siin', '##nnnnnnnnnn', '##n', '##snnn', '##iinn', '##nnsq', '##snlq', '##sllh', '##pqy', '##ylsn', '##ssssssss', '##yk', '##it', '##p']\n","No. of Tokens: 62\n","{'token_ids': [2, 15, 18215, 41, 3886, 288, 162, 1757, 8558, 473, 315, 6572, 42, 48, 5779, 25621, 26938, 335, 42, 10769, 3952, 252, 66, 42, 8015, 42, 10207, 22795, 5601, 10424, 315, 208, 2727, 21564, 373, 405, 264, 373, 405, 234, 212, 24010, 744, 18143, 328, 329, 5344, 12441, 30, 7403, 26966, 41, 4636, 24010, 27884, 11376, 6014, 4345, 25617, 2517, 258, 183, 40, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BtzyAMMABzQS","executionInfo":{"status":"ok","timestamp":1609880228699,"user_tz":-300,"elapsed":901,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}}},"source":["# the recommended batches size for BERT are 16,32 ... however on this dataset we are overfitting quite fast \r\n","# and smaller batches work like a regularization. \r\n","# You might play with adding another dropout layer instead.\r\n","\r\n","batch_size = 6"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"TQ30n7doAkV8","executionInfo":{"status":"ok","timestamp":1609880848194,"user_tz":-300,"elapsed":884,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}}},"source":["def convert_sequence_to_features(sequence, max_length_seq=200):\r\n","    tokenized = tokenizer.tokenize(sequence)\r\n","\r\n","    # print('tokenized', tokenized)\r\n","    # print(\"No. of Tokens:\", len(tokenized))\r\n","    # convert tokens to ids in WordPiece\r\n","    input_ids = tokenizer.convert_tokens_to_ids([\"[CLS]\"] + tokenized + [\"[SEP]\"])\r\n","    \r\n","    # precalculation of pad length, so that we can reuse it later on\r\n","    padding_length = max_length_seq - len(input_ids)\r\n","\r\n","    tokens_length = len(input_ids)\r\n","\r\n","    # map tokens to WordPiece dictionary and add pad token for those text shorter than our max length\r\n","    input_ids = input_ids + ([0] * padding_length)\r\n","\r\n","    # attention should focus just on sequence with non padded tokens\r\n","    attention_mask = [1] * tokens_length\r\n","\r\n","    # do not focus attention on padded tokens\r\n","    attention_mask = attention_mask + ([0] * padding_length)\r\n","\r\n","    # token types, needed for example for question answering, for our purpose we will just set 0 as we have just one sequence\r\n","    token_type_ids = [0] * max_length_seq\r\n","\r\n","    bert_input = {\r\n","        \"input_ids\": input_ids,\r\n","        \"token_type_ids\": token_type_ids,\r\n","        \"attention_mask\": attention_mask\r\n","    }\r\n","    return bert_input\r\n"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"ye4KlbrACIS2","executionInfo":{"status":"ok","timestamp":1609881050479,"user_tz":-300,"elapsed":902,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}}},"source":["# map to the expected input to TFBertForSequenceClassification, see here \r\n","def map_example_to_dict(input_ids, attention_masks, token_type_ids, labels):\r\n","  return {\r\n","      \"input_ids\": input_ids,\r\n","      \"token_type_ids\": token_type_ids,\r\n","      \"attention_mask\": attention_masks,\r\n","  }, labels\r\n","\r\n","def encode_examples(seqs, labels, max_seq_length=200, limit=-1):\r\n","\r\n","  # prepare list, so that we can build up final TensorFlow dataset from slices.\r\n","  input_ids_list = []\r\n","  token_type_ids_list = []\r\n","  attention_mask_list = []\r\n","  label_list = []\r\n","\r\n","  for seq, label in zip(seqs, labels):\r\n","\r\n","    bert_input = convert_sequence_to_features(seq, max_seq_length)\r\n","  \r\n","    input_ids_list.append(bert_input['input_ids'])\r\n","    token_type_ids_list.append(bert_input['token_type_ids'])\r\n","    attention_mask_list.append(bert_input['attention_mask'])\r\n","    label_list.append(label)\r\n","  \r\n","  return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_example_to_dict)\r\n"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"_hWSRFnpKKtl","executionInfo":{"status":"ok","timestamp":1609880261228,"user_tz":-300,"elapsed":901,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}}},"source":["train_num=int(len(rawdata)*0.9)\r\n","train_data=rawdata[0:train_num]\r\n","validation_data=rawdata[train_num:]"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dKtaOUWQLAs-","executionInfo":{"status":"ok","timestamp":1609880266686,"user_tz":-300,"elapsed":931,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}},"outputId":"5cfaf322-4fb7-43fc-959c-04dda951d6b1"},"source":["print(len(train_data), len(validation_data))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["28260 3140\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LIhECYKICYxW","executionInfo":{"status":"ok","timestamp":1609881627442,"user_tz":-300,"elapsed":280261,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}}},"source":["train_inputX = [i[0] for i in train_data]\r\n","train_inputY = [utils.convertlabels_to_binary(i[1]) for i in train_data]\r\n","train_encoded = encode_examples(train_inputX, train_inputY).shuffle(10000).batch(batch_size)\r\n","\r\n","val_inputX = [i[0] for i in validation_data]\r\n","val_inputY = [utils.convertlabels_to_binary(i[1]) for i in validation_data]\r\n","val_encoded = encode_examples(val_inputX, val_inputY).batch(batch_size)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aZb9jDAAJlHW","executionInfo":{"status":"ok","timestamp":1609881627449,"user_tz":-300,"elapsed":276865,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}},"outputId":"ff63f8db-911d-4278-9a75-d6cef9d8cc2f"},"source":["print(train_encoded)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["<BatchDataset shapes: ({input_ids: (None, 200), token_type_ids: (None, 200), attention_mask: (None, 200)}, (None, 200)), types: ({input_ids: tf.int32, token_type_ids: tf.int32, attention_mask: tf.int32}, tf.int32)>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W0VBoHGNbt71","executionInfo":{"status":"ok","timestamp":1609882555826,"user_tz":-300,"elapsed":844,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}}},"source":["from transformers import TFBertForSequenceClassification, TFPreTrainedModel\r\n","import tensorflow as tf"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JffesNv1by0A","executionInfo":{"status":"ok","timestamp":1609883593415,"user_tz":-300,"elapsed":2399,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}},"outputId":"27e62ed2-0a96-469e-92d3-9ca88edf582b"},"source":["\r\n","# recommended learning rate for Adam 5e-5, 3e-5, 2e-5\r\n","\r\n","learning_rate = 2e-5\r\n","\r\n","# we will do just 1 epoch for illustration, though multiple epochs might be better as long as we will not overfit the model\r\n","number_of_epochs = 1\r\n","\r\n","\r\n","# model initialization\r\n","model = TFBertForSequenceClassification.from_pretrained(\r\n","    'bert_thesis_experiments/pytorch_bert_pretrained_models/pytorch_model.bin',\r\n","    config='bert_thesis_experiments/pytorch_bert_pretrained_models/config.json',\r\n","    from_pt=True,\r\n","    output_attentions=False,\r\n","    output_hidden_states=False, \r\n","    num_labels=200)\r\n","\r\n","# classifier Adam recommended\r\n","optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\r\n","\r\n","# we do not have one-hot vectors, we can use sparce categorical cross entropy and accuracy\r\n","loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\r\n","metric = tf.keras.metrics.BinaryAccuracy('accuracy')\r\n","\r\n","model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"],"execution_count":64,"outputs":[{"output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n","- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tSfydw_QedoH","executionInfo":{"status":"ok","timestamp":1609883597025,"user_tz":-300,"elapsed":917,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}},"outputId":"b5a1d0c1-5ab5-400a-a4aa-ffe7ce14b6a9"},"source":["model.summary()"],"execution_count":65,"outputs":[{"output_type":"stream","text":["Model: \"tf_bert_for_sequence_classification_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bert (TFBertMainLayer)       multiple                  109482240 \n","_________________________________________________________________\n","dropout_265 (Dropout)        multiple                  0         \n","_________________________________________________________________\n","classifier (Dense)           multiple                  153800    \n","=================================================================\n","Total params: 109,636,040\n","Trainable params: 109,636,040\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x3g6LWssgRrO","executionInfo":{"status":"ok","timestamp":1609885018751,"user_tz":-300,"elapsed":1420827,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}},"outputId":"c564cc76-9fe0-47b6-a051-82b3dbad8644"},"source":["bert_history = model.fit(train_encoded, epochs=number_of_epochs, validation_data=val_encoded)"],"execution_count":66,"outputs":[{"output_type":"stream","text":["The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["4710/4710 [==============================] - ETA: 0s - loss: 0.9612 - accuracy: 0.7607"],"name":"stdout"},{"output_type":"stream","text":["The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4710/4710 [==============================] - 1420s 299ms/step - loss: 0.9612 - accuracy: 0.7607 - val_loss: 0.7234 - val_accuracy: 0.8095\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WEtXNHaTxsfS"},"source":["## Reference\r\n","1. https://medium.com/atheros/text-classification-with-transformers-in-tensorflow-2-bert-2f4f16eff5ad\r\n","2. https://github.com/atherosai/python-graphql-nlp-transformers/tree/master/notebooks/BERT%20fine-tunning%20in%20Tensorflow%202%20with%20Keras%20API"]}]}