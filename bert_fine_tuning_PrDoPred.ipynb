{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"bert_fine_tuning_PrDoPred.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5e943aef87f8441bba3269c94b3785e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fe8a7df053ae4cf4afd568c79018f039","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_233ed35c518142a08297f1c3a5e1debb","IPY_MODEL_3e0ad18f82364df0b17bfda7a827e517"]}},"fe8a7df053ae4cf4afd568c79018f039":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"800px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"233ed35c518142a08297f1c3a5e1debb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a01d1ca28b94465ca4d4d429774abc25","_dom_classes":[],"description":"Finding Max Seq Length: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":31400,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":31400,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_68ce046ce8a6430aae5db6b7ccf37f7e"}},"3e0ad18f82364df0b17bfda7a827e517":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_12a927df88e24314903356b089dcae19","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 31400/31400 [05:13&lt;00:00, 100.23it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_765984079426404a87cf0fa33f726ec2"}},"a01d1ca28b94465ca4d4d429774abc25":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"68ce046ce8a6430aae5db6b7ccf37f7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"12a927df88e24314903356b089dcae19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"765984079426404a87cf0fa33f726ec2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FsRwCEfWB6Tr","executionInfo":{"status":"ok","timestamp":1610170476971,"user_tz":-300,"elapsed":971,"user":{"displayName":"Addie doy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhANkDOFu5GL7-s1rnBGaHu2mCB4p0hV0ReV1po=s64","userId":"08116045324481674138"}},"outputId":"87395ee2-8f82-4c72-fe19-4bff0cb1060b"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sat Jan  9 05:34:37 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aa5ShOPHrTYI","executionInfo":{"status":"ok","timestamp":1610170479470,"user_tz":-300,"elapsed":922,"user":{"displayName":"Addie doy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhANkDOFu5GL7-s1rnBGaHu2mCB4p0hV0ReV1po=s64","userId":"08116045324481674138"}},"outputId":"32ce473d-6f7c-4557-8853-053ebe70039c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rg9sLayiuT4j"},"source":["!pip install bert-for-tf2 >> /dev/null"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y1CYxUIowMfh"},"source":["import os\n","import math\n","import datetime\n","\n","# from tqdm import tqdm\n","from tqdm.notebook import tqdm as tqdm\n","\n","import pandas as pd\n","import numpy as np\n","\n","import re\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from  tensorflow.keras.callbacks import EarlyStopping\n","\n","import bert\n","from bert import BertModelLayer\n","from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n","from bert.tokenization.bert_tokenization import FullTokenizer\n","\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RWzXUUncyPim","executionInfo":{"status":"ok","timestamp":1610170491603,"user_tz":-300,"elapsed":1071,"user":{"displayName":"Addie doy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhANkDOFu5GL7-s1rnBGaHu2mCB4p0hV0ReV1po=s64","userId":"08116045324481674138"}},"outputId":"1b3f2468-2e2c-4ac1-dcaf-ae887f171685"},"source":["cd \"/content/drive/My Drive/Colab Notebooks NU\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1FqifPUlm6cgaaWF0H2AQqipYJL1XcCct/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BnBsS0auStbG"},"source":["import bert_thesis_experiments.utils as utils\r\n","import bert_thesis_experiments.my_models as my_models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JqxVZDSPwX5P"},"source":["seqfile = 'DeepDom_Code/DeepDom-master/processed_seq.txt'; #file name of the processed sequence data (output from dataprocess.pl)\n","labelfile= 'DeepDom_Code/DeepDom-master/processed_label.txt'; #file name of the processed label data (output from dataprocess.pl)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EiTDX7LAlv9l"},"source":["(ids,seqs) = utils.process_inputseqs(seqfile)\n","(ids,labels) = utils.process_inputlabels(labelfile)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tCybP5WBr1-K"},"source":["# num_of_seq = 20000\n","# rawdata = list(zip(seqs[:num_of_seq],labels[:num_of_seq]))\n","# random.shuffle(rawdata)\n","\n","rawdata = list(zip(seqs,labels))\n","random.shuffle(rawdata)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NCkU_wYm1Aaw"},"source":["tokenizer = FullTokenizer(vocab_file=os.path.join(\"bert_thesis_experiments/working/\", \"protein_seq_words_uniref0.5_vsz30k_mfq2-vocab.txt\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Igep9DAN1dUZ","executionInfo":{"status":"ok","timestamp":1610170511071,"user_tz":-300,"elapsed":889,"user":{"displayName":"Addie doy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhANkDOFu5GL7-s1rnBGaHu2mCB4p0hV0ReV1po=s64","userId":"08116045324481674138"}},"outputId":"622e422f-fa76-411f-f5e9-90aceb52acdc"},"source":["seq_i = 51\n","print(rawdata[seq_i][0])\n","print(\"Number of tokens in seq\", len(tokenizer.tokenize(rawdata[seq_i][0])))\n","print(tokenizer.tokenize(rawdata[seq_i][0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MSSPILNTDDNNCVRVALRVRPLSKKEEAERSMEVVKYVDGEPQVIMGDNNQTFTFDYVFNGKSRQQEIFDDCVANLVDCLFEGYNSTILAYGQTGSGKTFTMGTTSTIGIPTEELGVIPRVIDFIYDKIDRKKDTHQLVLKVSFLELYNEEIRDMLNPYPTAGGLPIREKSNGEVYIPGLVEQIVRSRQQMEEALIRGS\n","Number of tokens in seq 72\n","['mss', '##pi', '##l', '##ntdd', '##nnc', '##vr', '##v', '##alrv', '##rpl', '##skk', '##eeae', '##rsm', '##evv', '##kyv', '##dgep', '##qvi', '##mgd', '##nnq', '##tf', '##tf', '##dy', '##vf', '##ngk', '##srqq', '##eifd', '##dc', '##v', '##anlv', '##dc', '##l', '##feg', '##ynst', '##ilay', '##gq', '##tgsgkt', '##ftm', '##gt', '##ts', '##tigi', '##pt', '##eelgv', '##ipr', '##vi', '##df', '##iy', '##dk', '##idr', '##kkdt', '##hq', '##l', '##vlkv', '##sfl', '##elyn', '##eeir', '##dm', '##l', '##npy', '##pt', '##aggl', '##pir', '##eksn', '##ge', '##vy', '##ipgl', '##ve', '##qiv', '##rsr', '##qqm', '##eeal', '##ir', '##g', '##s']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jMdM4bZG12zh","executionInfo":{"status":"ok","timestamp":1610170513301,"user_tz":-300,"elapsed":936,"user":{"displayName":"Addie doy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhANkDOFu5GL7-s1rnBGaHu2mCB4p0hV0ReV1po=s64","userId":"08116045324481674138"}},"outputId":"625221bd-7aad-4849-874b-b655024c044d"},"source":["tokens = tokenizer.tokenize(rawdata[seq_i][0])\n","tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n","token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","padded_token_ids = token_ids + [0] * (200 - len(token_ids))\n","print(len(padded_token_ids), padded_token_ids, sep='\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["200\n","[2, 2122, 238, 42, 22392, 3456, 278, 31, 16893, 870, 410, 4108, 2283, 510, 1869, 16997, 1317, 2128, 1962, 292, 292, 315, 333, 4169, 16746, 15881, 490, 31, 5881, 490, 42, 17731, 19792, 29044, 322, 18138, 3321, 252, 307, 16216, 219, 29716, 8954, 228, 281, 332, 259, 6728, 23277, 284, 42, 17635, 422, 25384, 10548, 399, 42, 2129, 219, 2879, 12769, 19357, 330, 370, 7512, 294, 16270, 803, 2679, 2044, 267, 30, 43, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FYTrwvIhB5SJ","executionInfo":{"status":"ok","timestamp":1610132519724,"user_tz":-300,"elapsed":944,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}},"outputId":"c024a8d1-b66e-40f6-93da-595e65eb7690"},"source":["# import importlib\r\n","# importlib.reload(my_models)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<module 'bert_thesis_experiments.my_models' from '/content/drive/My Drive/Colab Notebooks/bert_thesis_experiments/my_models.py'>"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":100,"referenced_widgets":["5e943aef87f8441bba3269c94b3785e3","fe8a7df053ae4cf4afd568c79018f039","233ed35c518142a08297f1c3a5e1debb","3e0ad18f82364df0b17bfda7a827e517","a01d1ca28b94465ca4d4d429774abc25","68ce046ce8a6430aae5db6b7ccf37f7e","12a927df88e24314903356b089dcae19","765984079426404a87cf0fa33f726ec2"]},"id":"4T9KnBxztzbG","executionInfo":{"status":"ok","timestamp":1610124178325,"user_tz":-300,"elapsed":230503,"user":{"displayName":"Ahmad Haseeb FastNU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxDqmODZ71n4jpArztC4dNYmzQJTeVBD6QySVzYQ=s64","userId":"10708169549409029420"}},"outputId":"7e536e21-cb6c-4e61-a8d8-1d3920273fe6"},"source":["max_seq_len = utils.find_max_seq_len(rawdata, tokenizer)\r\n","\r\n","print(\"\\nMax Seq Length:\", max_seq_len)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e943aef87f8441bba3269c94b3785e3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Finding Max Seq Length', layout=Layout(flex='2'), max=314â€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","Max Seq Length: 170\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kiamts_Za7t_","executionInfo":{"status":"ok","timestamp":1610170534529,"user_tz":-300,"elapsed":948,"user":{"displayName":"Addie doy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhANkDOFu5GL7-s1rnBGaHu2mCB4p0hV0ReV1po=s64","userId":"08116045324481674138"}},"outputId":"b360db5b-7ce8-43eb-d8d0-5891efbcc14c"},"source":["print(rawdata[seq_i][1])\n","print(rawdata[900][1])\n","print(rawdata[500][1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["11111111111111111111111111000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n","00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001111\n","00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001111111111111111111111111111111111111111100------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8BsD7jSgbcrP","executionInfo":{"status":"ok","timestamp":1610170548466,"user_tz":-300,"elapsed":1039,"user":{"displayName":"Addie doy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhANkDOFu5GL7-s1rnBGaHu2mCB4p0hV0ReV1po=s64","userId":"08116045324481674138"}},"outputId":"71666ca0-9cdd-47a0-b17f-8f63ecb644e1"},"source":["\n","label_array_1 = list(map(int, rawdata[500][1].replace('-', '0')))\n","print(label_array_1)\n","print(len(label_array_1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","200\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ystqQCj3r-yy"},"source":["inputX = [utils.convert_seq_ids(i[0], tokenizer, 200) for i in rawdata]\n","# inputY = [utils.convertlabels_to_categorical(i[1]) for i in rawdata]\n","inputY = [utils.convertlabels_to_binary(i[1]) for i in rawdata]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EPRl4mtDmOiz","executionInfo":{"status":"ok","timestamp":1610170773604,"user_tz":-300,"elapsed":217065,"user":{"displayName":"Addie doy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhANkDOFu5GL7-s1rnBGaHu2mCB4p0hV0ReV1po=s64","userId":"08116045324481674138"}},"outputId":"68cac1b9-50d7-4cba-c77d-43d9dda3da38"},"source":["print(\"Max length of sequence:\", len(inputX[seq_i]))\n","print(\"No of sequences\", len(inputX))\n","print(inputX[seq_i])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Max length of sequence: 200\n","No of sequences 31400\n","[2, 2122, 238, 42, 22392, 3456, 278, 31, 16893, 870, 410, 4108, 2283, 510, 1869, 16997, 1317, 2128, 1962, 292, 292, 315, 333, 4169, 16746, 15881, 490, 31, 5881, 490, 42, 17731, 19792, 29044, 322, 18138, 3321, 252, 307, 16216, 219, 29716, 8954, 228, 281, 332, 259, 6728, 23277, 284, 42, 17635, 422, 25384, 10548, 399, 42, 2129, 219, 2879, 12769, 19357, 330, 370, 7512, 294, 16270, 803, 2679, 2044, 267, 30, 43, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D4fc2M7Z5kKJ","executionInfo":{"status":"ok","timestamp":1610170774612,"user_tz":-300,"elapsed":215899,"user":{"displayName":"Addie doy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhANkDOFu5GL7-s1rnBGaHu2mCB4p0hV0ReV1po=s64","userId":"08116045324481674138"}},"outputId":"2531021a-cbc6-4961-b983-88526ba5a847"},"source":["data=list(zip(inputX,inputY))\n","random.seed(4)\n","random.shuffle(data)\n","random.shuffle(data)\n","    \n","train_num=int(len(inputX)*0.9)\n","train=data[0:train_num]\n","val=data[train_num:]\n","\n","trainX=np.array([i[0] for i in train])\n","trainY=np.array([i[1] for i in train])\n","# xx=np.dstack(trainX)\n","# xx=np.rollaxis(xx,-1)\n","\n","print(trainX.shape)   \n","print(trainY.shape) \n","\n","# yy=np.dstack(trainY)\n","# yy=np.rollaxis(yy,-1)\n","\n","# print(yy.shape)\n","    \n","valX=np.array([i[0] for i in val])\n","valY=np.array([i[1] for i in val])\n","# valX=np.dstack(valX)\n","# valX=np.rollaxis(valX,-1)\n","\n","# valY=np.dstack(valY)\n","# valY=np.rollaxis(valY,-1)\n","\n","vv=(valX,valY)\n","\n","print(\"\\n---Validation Data---\")\n","print(valX.shape)\n","print(valY.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(28260, 200)\n","(28260, 200)\n","\n","---Validation Data---\n","(3140, 200)\n","(3140, 200)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8FqSzoadwcrE"},"source":["bert_model_name = \"bert_H768_A12_uniref50_vocab30k_steps30k\"\n","\n","bert_ckpt_dir = os.path.join(\"bert_thesis_experiments/working/\", bert_model_name)\n","bert_ckpt_file = os.path.join(bert_ckpt_dir, \"model.ckpt-10000\")\n","bert_config_file = os.path.join(bert_ckpt_dir, \"bert_config.json\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"elw4xQmGYOMS"},"source":["def create_model_bilstm(max_seq_len, bert_ckpt_file):\n","\n","  with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n","      bc = StockBertConfig.from_json_string(reader.read())\n","      bert_params = map_stock_config_to_params(bc)\n","      bert_params.adapter_size = None\n","      bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n","        \n","  input_ids = keras.layers.Input(shape=(max_seq_len, ), dtype='int32', name=\"input_ids\")\n","  bert_output = bert(input_ids)\n","\n","  print(\"bert shape\", bert_output.shape)\n","\n","  classes = 200\n","\n","  x1 = keras.layers.Bidirectional(keras.layers.LSTM(100,return_sequences=True),merge_mode='sum')(bert_output)\n","#   x4 = keras.layers.Bidirectional(keras.layers.LSTM(3,return_sequences=True),merge_mode='sum')(bert_output)\n","    \n","  x2 = keras.layers.Bidirectional(keras.layers.LSTM(100,return_sequences=True),merge_mode='sum')(x1)\n","\n","  x3 = keras.layers.Bidirectional(keras.layers.LSTM(100,return_sequences=True),merge_mode='sum')(x2)\n","  x4 = keras.layers.Bidirectional(keras.layers.LSTM(3,return_sequences=True),merge_mode='sum')(x3)\n","\n","  output = keras.layers.Activation('softmax')(x4)\n","\n","\n","#   cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)\n","#   cls_out = keras.layers.Dropout(0.5)(cls_out)\n","#   logits = keras.layers.Dense(units=512, activation=\"tanh\")(cls_out)\n","#   logits = keras.layers.Dropout(0.5)(logits)\n","#   logits = keras.layers.Dense(units=classes, activation=\"sigmoid\")(logits)\n","\n","  model = keras.Model(inputs=input_ids, outputs=output)\n","  model.build(input_shape=(None, max_seq_len))\n","\n","  load_stock_weights(bert, bert_ckpt_file)\n","        \n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QwJK3O-u2D3Z"},"source":["def create_model(max_seq_len, bert_ckpt_file, bert_config_file):\n","\n","    with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n","        bc = StockBertConfig.from_json_string(reader.read())\n","        bert_params = map_stock_config_to_params(bc)\n","        bert_params.adapter_size = None\n","        bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n","    \n","    input_ids = keras.layers.Input(\n","        shape=(max_seq_len, ),\n","        dtype='int32',\n","        name=\"input_ids\"\n","    )\n","    bert_output = bert(input_ids)\n","    \n","    print(\"bert shape\", bert_output.shape)\n","\n","    classes = 200\n","\n","    # cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)\n","    cls_out = keras.layers.Flatten()(bert_output)\n","    # cls_out = keras.layers.Dropout(0.5)(cls_out)\n","    # logits = keras.layers.Dense(units=512, activation=\"tanh\")(cls_out)\n","    # logits = keras.layers.Dropout(0.5)(logits)\n","    logits = keras.layers.Dense(\n","        units=classes,\n","        activation=\"sigmoid\"\n","    )(cls_out)\n","\n","    model = keras.Model(inputs=input_ids, outputs=logits)\n","\n","\n","    load_stock_weights(bert, bert_ckpt_file)\n","    model.build(input_shape=(None, max_seq_len))\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bRUdvnyrQH8h"},"source":["def create_model_fcnn(max_seq_len, bert_ckpt_file, bert_config_file):\r\n","\r\n","    with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\r\n","        bc = StockBertConfig.from_json_string(reader.read())\r\n","        bert_params = map_stock_config_to_params(bc)\r\n","        bert_params.adapter_size = None\r\n","        bert = BertModelLayer.from_params(bert_params, name=\"bert\")\r\n","    \r\n","    input_ids = keras.layers.Input(\r\n","        shape=(max_seq_len, ),\r\n","        dtype='int32',\r\n","        name=\"input_ids\"\r\n","    )\r\n","    bert_output = bert(input_ids)\r\n","    \r\n","    print(\"bert shape\", bert_output.shape)\r\n","\r\n","    classes = 200\r\n","\r\n","    # cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)\r\n","    cls_out = keras.layers.Flatten()(bert_output)\r\n","    logits = keras.layers.Dense(units=1500, activation=\"relu\")(cls_out)\r\n","    logits = keras.layers.Dropout(0.5)(logits)\r\n","    for i in range(0,3):\r\n","        logits = keras.layers.Dense(units=1500)(logits)\r\n","        logits = keras.layers.Activation(\"relu\")(logits)\r\n","    logits = keras.layers.Dropout(0.5)(logits)\r\n","    logits = keras.layers.Dense(\r\n","        units=classes,\r\n","        activation=\"sigmoid\"\r\n","    )(logits)\r\n","\r\n","    model = keras.Model(inputs=input_ids, outputs=logits, name=\"bert_fcnn\")\r\n","\r\n","\r\n","    load_stock_weights(bert, bert_ckpt_file)\r\n","    model.build(input_shape=(None, max_seq_len))\r\n","\r\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ofqbnjNe3z6J","executionInfo":{"status":"ok","timestamp":1610181654482,"user_tz":-300,"elapsed":4718,"user":{"displayName":"Addie doy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhANkDOFu5GL7-s1rnBGaHu2mCB4p0hV0ReV1po=s64","userId":"08116045324481674138"}},"outputId":"1ae86a02-e933-49e9-ed41-5e29bc4d08be"},"source":["# model = my_models.create_model_bilstm(200, bert_ckpt_file, bert_config_file)\r\n","model = create_model_fcnn(200, bert_ckpt_file, bert_config_file)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["bert shape (None, 200, 768)\n","Done loading 196 BERT weights from: bert_thesis_experiments/working/bert_H768_A12_uniref50_vocab30k_steps30k/model.ckpt-10000 into <bert.model.BertModelLayer object at 0x7fc213a73b00> (prefix:bert). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n","Unused weights from checkpoint: \n","\tbert/embeddings/LayerNorm/beta/adam_m\n","\tbert/embeddings/LayerNorm/beta/adam_v\n","\tbert/embeddings/LayerNorm/gamma/adam_m\n","\tbert/embeddings/LayerNorm/gamma/adam_v\n","\tbert/embeddings/position_embeddings/adam_m\n","\tbert/embeddings/position_embeddings/adam_v\n","\tbert/embeddings/token_type_embeddings\n","\tbert/embeddings/token_type_embeddings/adam_m\n","\tbert/embeddings/token_type_embeddings/adam_v\n","\tbert/embeddings/word_embeddings/adam_m\n","\tbert/embeddings/word_embeddings/adam_v\n","\tbert/encoder/layer_0/attention/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_0/attention/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_0/attention/output/dense/bias/adam_m\n","\tbert/encoder/layer_0/attention/output/dense/bias/adam_v\n","\tbert/encoder/layer_0/attention/output/dense/kernel/adam_m\n","\tbert/encoder/layer_0/attention/output/dense/kernel/adam_v\n","\tbert/encoder/layer_0/attention/self/key/bias/adam_m\n","\tbert/encoder/layer_0/attention/self/key/bias/adam_v\n","\tbert/encoder/layer_0/attention/self/key/kernel/adam_m\n","\tbert/encoder/layer_0/attention/self/key/kernel/adam_v\n","\tbert/encoder/layer_0/attention/self/query/bias/adam_m\n","\tbert/encoder/layer_0/attention/self/query/bias/adam_v\n","\tbert/encoder/layer_0/attention/self/query/kernel/adam_m\n","\tbert/encoder/layer_0/attention/self/query/kernel/adam_v\n","\tbert/encoder/layer_0/attention/self/value/bias/adam_m\n","\tbert/encoder/layer_0/attention/self/value/bias/adam_v\n","\tbert/encoder/layer_0/attention/self/value/kernel/adam_m\n","\tbert/encoder/layer_0/attention/self/value/kernel/adam_v\n","\tbert/encoder/layer_0/intermediate/dense/bias/adam_m\n","\tbert/encoder/layer_0/intermediate/dense/bias/adam_v\n","\tbert/encoder/layer_0/intermediate/dense/kernel/adam_m\n","\tbert/encoder/layer_0/intermediate/dense/kernel/adam_v\n","\tbert/encoder/layer_0/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_0/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_0/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_0/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_0/output/dense/bias/adam_m\n","\tbert/encoder/layer_0/output/dense/bias/adam_v\n","\tbert/encoder/layer_0/output/dense/kernel/adam_m\n","\tbert/encoder/layer_0/output/dense/kernel/adam_v\n","\tbert/encoder/layer_1/attention/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_1/attention/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_1/attention/output/dense/bias/adam_m\n","\tbert/encoder/layer_1/attention/output/dense/bias/adam_v\n","\tbert/encoder/layer_1/attention/output/dense/kernel/adam_m\n","\tbert/encoder/layer_1/attention/output/dense/kernel/adam_v\n","\tbert/encoder/layer_1/attention/self/key/bias/adam_m\n","\tbert/encoder/layer_1/attention/self/key/bias/adam_v\n","\tbert/encoder/layer_1/attention/self/key/kernel/adam_m\n","\tbert/encoder/layer_1/attention/self/key/kernel/adam_v\n","\tbert/encoder/layer_1/attention/self/query/bias/adam_m\n","\tbert/encoder/layer_1/attention/self/query/bias/adam_v\n","\tbert/encoder/layer_1/attention/self/query/kernel/adam_m\n","\tbert/encoder/layer_1/attention/self/query/kernel/adam_v\n","\tbert/encoder/layer_1/attention/self/value/bias/adam_m\n","\tbert/encoder/layer_1/attention/self/value/bias/adam_v\n","\tbert/encoder/layer_1/attention/self/value/kernel/adam_m\n","\tbert/encoder/layer_1/attention/self/value/kernel/adam_v\n","\tbert/encoder/layer_1/intermediate/dense/bias/adam_m\n","\tbert/encoder/layer_1/intermediate/dense/bias/adam_v\n","\tbert/encoder/layer_1/intermediate/dense/kernel/adam_m\n","\tbert/encoder/layer_1/intermediate/dense/kernel/adam_v\n","\tbert/encoder/layer_1/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_1/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_1/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_1/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_1/output/dense/bias/adam_m\n","\tbert/encoder/layer_1/output/dense/bias/adam_v\n","\tbert/encoder/layer_1/output/dense/kernel/adam_m\n","\tbert/encoder/layer_1/output/dense/kernel/adam_v\n","\tbert/encoder/layer_10/attention/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_10/attention/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_10/attention/output/dense/bias/adam_m\n","\tbert/encoder/layer_10/attention/output/dense/bias/adam_v\n","\tbert/encoder/layer_10/attention/output/dense/kernel/adam_m\n","\tbert/encoder/layer_10/attention/output/dense/kernel/adam_v\n","\tbert/encoder/layer_10/attention/self/key/bias/adam_m\n","\tbert/encoder/layer_10/attention/self/key/bias/adam_v\n","\tbert/encoder/layer_10/attention/self/key/kernel/adam_m\n","\tbert/encoder/layer_10/attention/self/key/kernel/adam_v\n","\tbert/encoder/layer_10/attention/self/query/bias/adam_m\n","\tbert/encoder/layer_10/attention/self/query/bias/adam_v\n","\tbert/encoder/layer_10/attention/self/query/kernel/adam_m\n","\tbert/encoder/layer_10/attention/self/query/kernel/adam_v\n","\tbert/encoder/layer_10/attention/self/value/bias/adam_m\n","\tbert/encoder/layer_10/attention/self/value/bias/adam_v\n","\tbert/encoder/layer_10/attention/self/value/kernel/adam_m\n","\tbert/encoder/layer_10/attention/self/value/kernel/adam_v\n","\tbert/encoder/layer_10/intermediate/dense/bias/adam_m\n","\tbert/encoder/layer_10/intermediate/dense/bias/adam_v\n","\tbert/encoder/layer_10/intermediate/dense/kernel/adam_m\n","\tbert/encoder/layer_10/intermediate/dense/kernel/adam_v\n","\tbert/encoder/layer_10/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_10/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_10/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_10/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_10/output/dense/bias/adam_m\n","\tbert/encoder/layer_10/output/dense/bias/adam_v\n","\tbert/encoder/layer_10/output/dense/kernel/adam_m\n","\tbert/encoder/layer_10/output/dense/kernel/adam_v\n","\tbert/encoder/layer_11/attention/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_11/attention/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_11/attention/output/dense/bias/adam_m\n","\tbert/encoder/layer_11/attention/output/dense/bias/adam_v\n","\tbert/encoder/layer_11/attention/output/dense/kernel/adam_m\n","\tbert/encoder/layer_11/attention/output/dense/kernel/adam_v\n","\tbert/encoder/layer_11/attention/self/key/bias/adam_m\n","\tbert/encoder/layer_11/attention/self/key/bias/adam_v\n","\tbert/encoder/layer_11/attention/self/key/kernel/adam_m\n","\tbert/encoder/layer_11/attention/self/key/kernel/adam_v\n","\tbert/encoder/layer_11/attention/self/query/bias/adam_m\n","\tbert/encoder/layer_11/attention/self/query/bias/adam_v\n","\tbert/encoder/layer_11/attention/self/query/kernel/adam_m\n","\tbert/encoder/layer_11/attention/self/query/kernel/adam_v\n","\tbert/encoder/layer_11/attention/self/value/bias/adam_m\n","\tbert/encoder/layer_11/attention/self/value/bias/adam_v\n","\tbert/encoder/layer_11/attention/self/value/kernel/adam_m\n","\tbert/encoder/layer_11/attention/self/value/kernel/adam_v\n","\tbert/encoder/layer_11/intermediate/dense/bias/adam_m\n","\tbert/encoder/layer_11/intermediate/dense/bias/adam_v\n","\tbert/encoder/layer_11/intermediate/dense/kernel/adam_m\n","\tbert/encoder/layer_11/intermediate/dense/kernel/adam_v\n","\tbert/encoder/layer_11/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_11/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_11/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_11/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_11/output/dense/bias/adam_m\n","\tbert/encoder/layer_11/output/dense/bias/adam_v\n","\tbert/encoder/layer_11/output/dense/kernel/adam_m\n","\tbert/encoder/layer_11/output/dense/kernel/adam_v\n","\tbert/encoder/layer_2/attention/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_2/attention/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_2/attention/output/dense/bias/adam_m\n","\tbert/encoder/layer_2/attention/output/dense/bias/adam_v\n","\tbert/encoder/layer_2/attention/output/dense/kernel/adam_m\n","\tbert/encoder/layer_2/attention/output/dense/kernel/adam_v\n","\tbert/encoder/layer_2/attention/self/key/bias/adam_m\n","\tbert/encoder/layer_2/attention/self/key/bias/adam_v\n","\tbert/encoder/layer_2/attention/self/key/kernel/adam_m\n","\tbert/encoder/layer_2/attention/self/key/kernel/adam_v\n","\tbert/encoder/layer_2/attention/self/query/bias/adam_m\n","\tbert/encoder/layer_2/attention/self/query/bias/adam_v\n","\tbert/encoder/layer_2/attention/self/query/kernel/adam_m\n","\tbert/encoder/layer_2/attention/self/query/kernel/adam_v\n","\tbert/encoder/layer_2/attention/self/value/bias/adam_m\n","\tbert/encoder/layer_2/attention/self/value/bias/adam_v\n","\tbert/encoder/layer_2/attention/self/value/kernel/adam_m\n","\tbert/encoder/layer_2/attention/self/value/kernel/adam_v\n","\tbert/encoder/layer_2/intermediate/dense/bias/adam_m\n","\tbert/encoder/layer_2/intermediate/dense/bias/adam_v\n","\tbert/encoder/layer_2/intermediate/dense/kernel/adam_m\n","\tbert/encoder/layer_2/intermediate/dense/kernel/adam_v\n","\tbert/encoder/layer_2/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_2/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_2/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_2/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_2/output/dense/bias/adam_m\n","\tbert/encoder/layer_2/output/dense/bias/adam_v\n","\tbert/encoder/layer_2/output/dense/kernel/adam_m\n","\tbert/encoder/layer_2/output/dense/kernel/adam_v\n","\tbert/encoder/layer_3/attention/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_3/attention/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_3/attention/output/dense/bias/adam_m\n","\tbert/encoder/layer_3/attention/output/dense/bias/adam_v\n","\tbert/encoder/layer_3/attention/output/dense/kernel/adam_m\n","\tbert/encoder/layer_3/attention/output/dense/kernel/adam_v\n","\tbert/encoder/layer_3/attention/self/key/bias/adam_m\n","\tbert/encoder/layer_3/attention/self/key/bias/adam_v\n","\tbert/encoder/layer_3/attention/self/key/kernel/adam_m\n","\tbert/encoder/layer_3/attention/self/key/kernel/adam_v\n","\tbert/encoder/layer_3/attention/self/query/bias/adam_m\n","\tbert/encoder/layer_3/attention/self/query/bias/adam_v\n","\tbert/encoder/layer_3/attention/self/query/kernel/adam_m\n","\tbert/encoder/layer_3/attention/self/query/kernel/adam_v\n","\tbert/encoder/layer_3/attention/self/value/bias/adam_m\n","\tbert/encoder/layer_3/attention/self/value/bias/adam_v\n","\tbert/encoder/layer_3/attention/self/value/kernel/adam_m\n","\tbert/encoder/layer_3/attention/self/value/kernel/adam_v\n","\tbert/encoder/layer_3/intermediate/dense/bias/adam_m\n","\tbert/encoder/layer_3/intermediate/dense/bias/adam_v\n","\tbert/encoder/layer_3/intermediate/dense/kernel/adam_m\n","\tbert/encoder/layer_3/intermediate/dense/kernel/adam_v\n","\tbert/encoder/layer_3/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_3/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_3/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_3/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_3/output/dense/bias/adam_m\n","\tbert/encoder/layer_3/output/dense/bias/adam_v\n","\tbert/encoder/layer_3/output/dense/kernel/adam_m\n","\tbert/encoder/layer_3/output/dense/kernel/adam_v\n","\tbert/encoder/layer_4/attention/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_4/attention/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_4/attention/output/dense/bias/adam_m\n","\tbert/encoder/layer_4/attention/output/dense/bias/adam_v\n","\tbert/encoder/layer_4/attention/output/dense/kernel/adam_m\n","\tbert/encoder/layer_4/attention/output/dense/kernel/adam_v\n","\tbert/encoder/layer_4/attention/self/key/bias/adam_m\n","\tbert/encoder/layer_4/attention/self/key/bias/adam_v\n","\tbert/encoder/layer_4/attention/self/key/kernel/adam_m\n","\tbert/encoder/layer_4/attention/self/key/kernel/adam_v\n","\tbert/encoder/layer_4/attention/self/query/bias/adam_m\n","\tbert/encoder/layer_4/attention/self/query/bias/adam_v\n","\tbert/encoder/layer_4/attention/self/query/kernel/adam_m\n","\tbert/encoder/layer_4/attention/self/query/kernel/adam_v\n","\tbert/encoder/layer_4/attention/self/value/bias/adam_m\n","\tbert/encoder/layer_4/attention/self/value/bias/adam_v\n","\tbert/encoder/layer_4/attention/self/value/kernel/adam_m\n","\tbert/encoder/layer_4/attention/self/value/kernel/adam_v\n","\tbert/encoder/layer_4/intermediate/dense/bias/adam_m\n","\tbert/encoder/layer_4/intermediate/dense/bias/adam_v\n","\tbert/encoder/layer_4/intermediate/dense/kernel/adam_m\n","\tbert/encoder/layer_4/intermediate/dense/kernel/adam_v\n","\tbert/encoder/layer_4/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_4/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_4/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_4/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_4/output/dense/bias/adam_m\n","\tbert/encoder/layer_4/output/dense/bias/adam_v\n","\tbert/encoder/layer_4/output/dense/kernel/adam_m\n","\tbert/encoder/layer_4/output/dense/kernel/adam_v\n","\tbert/encoder/layer_5/attention/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_5/attention/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_5/attention/output/dense/bias/adam_m\n","\tbert/encoder/layer_5/attention/output/dense/bias/adam_v\n","\tbert/encoder/layer_5/attention/output/dense/kernel/adam_m\n","\tbert/encoder/layer_5/attention/output/dense/kernel/adam_v\n","\tbert/encoder/layer_5/attention/self/key/bias/adam_m\n","\tbert/encoder/layer_5/attention/self/key/bias/adam_v\n","\tbert/encoder/layer_5/attention/self/key/kernel/adam_m\n","\tbert/encoder/layer_5/attention/self/key/kernel/adam_v\n","\tbert/encoder/layer_5/attention/self/query/bias/adam_m\n","\tbert/encoder/layer_5/attention/self/query/bias/adam_v\n","\tbert/encoder/layer_5/attention/self/query/kernel/adam_m\n","\tbert/encoder/layer_5/attention/self/query/kernel/adam_v\n","\tbert/encoder/layer_5/attention/self/value/bias/adam_m\n","\tbert/encoder/layer_5/attention/self/value/bias/adam_v\n","\tbert/encoder/layer_5/attention/self/value/kernel/adam_m\n","\tbert/encoder/layer_5/attention/self/value/kernel/adam_v\n","\tbert/encoder/layer_5/intermediate/dense/bias/adam_m\n","\tbert/encoder/layer_5/intermediate/dense/bias/adam_v\n","\tbert/encoder/layer_5/intermediate/dense/kernel/adam_m\n","\tbert/encoder/layer_5/intermediate/dense/kernel/adam_v\n","\tbert/encoder/layer_5/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_5/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_5/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_5/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_5/output/dense/bias/adam_m\n","\tbert/encoder/layer_5/output/dense/bias/adam_v\n","\tbert/encoder/layer_5/output/dense/kernel/adam_m\n","\tbert/encoder/layer_5/output/dense/kernel/adam_v\n","\tbert/encoder/layer_6/attention/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_6/attention/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_6/attention/output/dense/bias/adam_m\n","\tbert/encoder/layer_6/attention/output/dense/bias/adam_v\n","\tbert/encoder/layer_6/attention/output/dense/kernel/adam_m\n","\tbert/encoder/layer_6/attention/output/dense/kernel/adam_v\n","\tbert/encoder/layer_6/attention/self/key/bias/adam_m\n","\tbert/encoder/layer_6/attention/self/key/bias/adam_v\n","\tbert/encoder/layer_6/attention/self/key/kernel/adam_m\n","\tbert/encoder/layer_6/attention/self/key/kernel/adam_v\n","\tbert/encoder/layer_6/attention/self/query/bias/adam_m\n","\tbert/encoder/layer_6/attention/self/query/bias/adam_v\n","\tbert/encoder/layer_6/attention/self/query/kernel/adam_m\n","\tbert/encoder/layer_6/attention/self/query/kernel/adam_v\n","\tbert/encoder/layer_6/attention/self/value/bias/adam_m\n","\tbert/encoder/layer_6/attention/self/value/bias/adam_v\n","\tbert/encoder/layer_6/attention/self/value/kernel/adam_m\n","\tbert/encoder/layer_6/attention/self/value/kernel/adam_v\n","\tbert/encoder/layer_6/intermediate/dense/bias/adam_m\n","\tbert/encoder/layer_6/intermediate/dense/bias/adam_v\n","\tbert/encoder/layer_6/intermediate/dense/kernel/adam_m\n","\tbert/encoder/layer_6/intermediate/dense/kernel/adam_v\n","\tbert/encoder/layer_6/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_6/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_6/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_6/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_6/output/dense/bias/adam_m\n","\tbert/encoder/layer_6/output/dense/bias/adam_v\n","\tbert/encoder/layer_6/output/dense/kernel/adam_m\n","\tbert/encoder/layer_6/output/dense/kernel/adam_v\n","\tbert/encoder/layer_7/attention/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_7/attention/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_7/attention/output/dense/bias/adam_m\n","\tbert/encoder/layer_7/attention/output/dense/bias/adam_v\n","\tbert/encoder/layer_7/attention/output/dense/kernel/adam_m\n","\tbert/encoder/layer_7/attention/output/dense/kernel/adam_v\n","\tbert/encoder/layer_7/attention/self/key/bias/adam_m\n","\tbert/encoder/layer_7/attention/self/key/bias/adam_v\n","\tbert/encoder/layer_7/attention/self/key/kernel/adam_m\n","\tbert/encoder/layer_7/attention/self/key/kernel/adam_v\n","\tbert/encoder/layer_7/attention/self/query/bias/adam_m\n","\tbert/encoder/layer_7/attention/self/query/bias/adam_v\n","\tbert/encoder/layer_7/attention/self/query/kernel/adam_m\n","\tbert/encoder/layer_7/attention/self/query/kernel/adam_v\n","\tbert/encoder/layer_7/attention/self/value/bias/adam_m\n","\tbert/encoder/layer_7/attention/self/value/bias/adam_v\n","\tbert/encoder/layer_7/attention/self/value/kernel/adam_m\n","\tbert/encoder/layer_7/attention/self/value/kernel/adam_v\n","\tbert/encoder/layer_7/intermediate/dense/bias/adam_m\n","\tbert/encoder/layer_7/intermediate/dense/bias/adam_v\n","\tbert/encoder/layer_7/intermediate/dense/kernel/adam_m\n","\tbert/encoder/layer_7/intermediate/dense/kernel/adam_v\n","\tbert/encoder/layer_7/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_7/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_7/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_7/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_7/output/dense/bias/adam_m\n","\tbert/encoder/layer_7/output/dense/bias/adam_v\n","\tbert/encoder/layer_7/output/dense/kernel/adam_m\n","\tbert/encoder/layer_7/output/dense/kernel/adam_v\n","\tbert/encoder/layer_8/attention/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_8/attention/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_8/attention/output/dense/bias/adam_m\n","\tbert/encoder/layer_8/attention/output/dense/bias/adam_v\n","\tbert/encoder/layer_8/attention/output/dense/kernel/adam_m\n","\tbert/encoder/layer_8/attention/output/dense/kernel/adam_v\n","\tbert/encoder/layer_8/attention/self/key/bias/adam_m\n","\tbert/encoder/layer_8/attention/self/key/bias/adam_v\n","\tbert/encoder/layer_8/attention/self/key/kernel/adam_m\n","\tbert/encoder/layer_8/attention/self/key/kernel/adam_v\n","\tbert/encoder/layer_8/attention/self/query/bias/adam_m\n","\tbert/encoder/layer_8/attention/self/query/bias/adam_v\n","\tbert/encoder/layer_8/attention/self/query/kernel/adam_m\n","\tbert/encoder/layer_8/attention/self/query/kernel/adam_v\n","\tbert/encoder/layer_8/attention/self/value/bias/adam_m\n","\tbert/encoder/layer_8/attention/self/value/bias/adam_v\n","\tbert/encoder/layer_8/attention/self/value/kernel/adam_m\n","\tbert/encoder/layer_8/attention/self/value/kernel/adam_v\n","\tbert/encoder/layer_8/intermediate/dense/bias/adam_m\n","\tbert/encoder/layer_8/intermediate/dense/bias/adam_v\n","\tbert/encoder/layer_8/intermediate/dense/kernel/adam_m\n","\tbert/encoder/layer_8/intermediate/dense/kernel/adam_v\n","\tbert/encoder/layer_8/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_8/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_8/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_8/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_8/output/dense/bias/adam_m\n","\tbert/encoder/layer_8/output/dense/bias/adam_v\n","\tbert/encoder/layer_8/output/dense/kernel/adam_m\n","\tbert/encoder/layer_8/output/dense/kernel/adam_v\n","\tbert/encoder/layer_9/attention/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_9/attention/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_9/attention/output/dense/bias/adam_m\n","\tbert/encoder/layer_9/attention/output/dense/bias/adam_v\n","\tbert/encoder/layer_9/attention/output/dense/kernel/adam_m\n","\tbert/encoder/layer_9/attention/output/dense/kernel/adam_v\n","\tbert/encoder/layer_9/attention/self/key/bias/adam_m\n","\tbert/encoder/layer_9/attention/self/key/bias/adam_v\n","\tbert/encoder/layer_9/attention/self/key/kernel/adam_m\n","\tbert/encoder/layer_9/attention/self/key/kernel/adam_v\n","\tbert/encoder/layer_9/attention/self/query/bias/adam_m\n","\tbert/encoder/layer_9/attention/self/query/bias/adam_v\n","\tbert/encoder/layer_9/attention/self/query/kernel/adam_m\n","\tbert/encoder/layer_9/attention/self/query/kernel/adam_v\n","\tbert/encoder/layer_9/attention/self/value/bias/adam_m\n","\tbert/encoder/layer_9/attention/self/value/bias/adam_v\n","\tbert/encoder/layer_9/attention/self/value/kernel/adam_m\n","\tbert/encoder/layer_9/attention/self/value/kernel/adam_v\n","\tbert/encoder/layer_9/intermediate/dense/bias/adam_m\n","\tbert/encoder/layer_9/intermediate/dense/bias/adam_v\n","\tbert/encoder/layer_9/intermediate/dense/kernel/adam_m\n","\tbert/encoder/layer_9/intermediate/dense/kernel/adam_v\n","\tbert/encoder/layer_9/output/LayerNorm/beta/adam_m\n","\tbert/encoder/layer_9/output/LayerNorm/beta/adam_v\n","\tbert/encoder/layer_9/output/LayerNorm/gamma/adam_m\n","\tbert/encoder/layer_9/output/LayerNorm/gamma/adam_v\n","\tbert/encoder/layer_9/output/dense/bias/adam_m\n","\tbert/encoder/layer_9/output/dense/bias/adam_v\n","\tbert/encoder/layer_9/output/dense/kernel/adam_m\n","\tbert/encoder/layer_9/output/dense/kernel/adam_v\n","\tbert/pooler/dense/bias\n","\tbert/pooler/dense/bias/adam_m\n","\tbert/pooler/dense/bias/adam_v\n","\tbert/pooler/dense/kernel\n","\tbert/pooler/dense/kernel/adam_m\n","\tbert/pooler/dense/kernel/adam_v\n","\tcls/predictions/output_bias\n","\tcls/predictions/output_bias/adam_m\n","\tcls/predictions/output_bias/adam_v\n","\tcls/predictions/transform/LayerNorm/beta\n","\tcls/predictions/transform/LayerNorm/beta/adam_m\n","\tcls/predictions/transform/LayerNorm/beta/adam_v\n","\tcls/predictions/transform/LayerNorm/gamma\n","\tcls/predictions/transform/LayerNorm/gamma/adam_m\n","\tcls/predictions/transform/LayerNorm/gamma/adam_v\n","\tcls/predictions/transform/dense/bias\n","\tcls/predictions/transform/dense/bias/adam_m\n","\tcls/predictions/transform/dense/bias/adam_v\n","\tcls/predictions/transform/dense/kernel\n","\tcls/predictions/transform/dense/kernel/adam_m\n","\tcls/predictions/transform/dense/kernel/adam_v\n","\tcls/seq_relationship/output_bias\n","\tcls/seq_relationship/output_bias/adam_m\n","\tcls/seq_relationship/output_bias/adam_v\n","\tcls/seq_relationship/output_weights\n","\tcls/seq_relationship/output_weights/adam_m\n","\tcls/seq_relationship/output_weights/adam_v\n","\tglobal_step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z-iXOQJ537Ag","executionInfo":{"status":"ok","timestamp":1610181656872,"user_tz":-300,"elapsed":948,"user":{"displayName":"Addie doy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhANkDOFu5GL7-s1rnBGaHu2mCB4p0hV0ReV1po=s64","userId":"08116045324481674138"}},"outputId":"d9610ddd-78d6-46c2-fe66-855ff659590d"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"bert_fcnn\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_ids (InputLayer)       [(None, 200)]             0         \n","_________________________________________________________________\n","bert (BertModelLayer)        (None, 200, 768)          108890112 \n","_________________________________________________________________\n","flatten_4 (Flatten)          (None, 153600)            0         \n","_________________________________________________________________\n","dense_36 (Dense)             (None, 1500)              230401500 \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 1500)              0         \n","_________________________________________________________________\n","dense_37 (Dense)             (None, 1500)              2251500   \n","_________________________________________________________________\n","activation_15 (Activation)   (None, 1500)              0         \n","_________________________________________________________________\n","dense_38 (Dense)             (None, 1500)              2251500   \n","_________________________________________________________________\n","activation_16 (Activation)   (None, 1500)              0         \n","_________________________________________________________________\n","dense_39 (Dense)             (None, 1500)              2251500   \n","_________________________________________________________________\n","activation_17 (Activation)   (None, 1500)              0         \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 1500)              0         \n","_________________________________________________________________\n","dense_40 (Dense)             (None, 200)               300200    \n","=================================================================\n","Total params: 346,346,312\n","Trainable params: 346,346,312\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-6Gx4Cpw5Mum","executionInfo":{"status":"ok","timestamp":1610190686179,"user_tz":-300,"elapsed":8942356,"user":{"displayName":"Addie doy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhANkDOFu5GL7-s1rnBGaHu2mCB4p0hV0ReV1po=s64","userId":"08116045324481674138"}},"outputId":"6379ea2f-c0b4-4de0-ae4d-03355eaf52c3"},"source":["early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n","model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False), optimizer=keras.optimizers.Adam(learning_rate=2e-5), \n","              metrics=[keras.metrics.BinaryAccuracy(threshold=0.5)])\n","# model.compile(loss='binary_crossentropy',optimizer=keras.optimizers.Adam(learning_rate=2e-5), metrics=['accuracy'])\n","\n","fitHistory_batch = model.fit(x=trainX,y=trainY, batch_size=16, validation_data=vv, epochs=5, callbacks=[early_stopping])\n","# fitHistory_batch = model.fit(x=trainX, y=yy, batch_size=32, validation_data=vv, epochs=3, callbacks=[early_stopping])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","1767/1767 [==============================] - 1805s 1s/step - loss: 0.5248 - binary_accuracy: 0.7883 - val_loss: 0.5251 - val_binary_accuracy: 0.8194\n","Epoch 2/5\n","1767/1767 [==============================] - 1786s 1s/step - loss: 0.4803 - binary_accuracy: 0.8191 - val_loss: 0.5060 - val_binary_accuracy: 0.8198\n","Epoch 3/5\n","1767/1767 [==============================] - 1783s 1s/step - loss: 0.4724 - binary_accuracy: 0.8207 - val_loss: 0.4966 - val_binary_accuracy: 0.8212\n","Epoch 4/5\n","1767/1767 [==============================] - 1783s 1s/step - loss: 0.4681 - binary_accuracy: 0.8212 - val_loss: 0.5009 - val_binary_accuracy: 0.8223\n","Epoch 5/5\n","1767/1767 [==============================] - 1784s 1s/step - loss: 0.4665 - binary_accuracy: 0.8217 - val_loss: 0.4876 - val_binary_accuracy: 0.8219\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RfwcPMi1AZ1i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610190833077,"user_tz":-300,"elapsed":145684,"user":{"displayName":"Addie doy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhANkDOFu5GL7-s1rnBGaHu2mCB4p0hV0ReV1po=s64","userId":"08116045324481674138"}},"outputId":"291ed151-dbc3-4752-c21d-f24cb83f7516"},"source":["model.save(\"bert-768-ConDo_fcnn_flatten_stp30k_voc30k_epoch5_bsz16\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.embeddings.Embedding object at 0x7fc21420a828>, because it is not built.\n","INFO:tensorflow:Assets written to: bert-768-ConDo_fcnn_flatten_stp30k_voc30k_epoch5_bsz16/assets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b4wwSLQR9siY"},"source":["!cp bert_thesis_experiments/working/ibert_config.json bert_thesis_experiments/working/bert_H512_A8_uniref50_vocab80k_steps10k"],"execution_count":null,"outputs":[]}]}